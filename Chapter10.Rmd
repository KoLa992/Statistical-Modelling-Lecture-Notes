---
title: "Basic Consepts of Hypothesis Testing"
author: "László Kovács"
date: "22/03/2025"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. A hipotézisvizsgálat alapgondolata

Istenigazából a **hipotézisvizsgálat** csak egy **alternatív mód a konfidencia-intervallumok mellett egy statisztikai mutatószám (paraméter) mintavételi hibájának figyelembe vételére**, amikor a mutatószám egy mintából számított értékéből akarjuk megismerni a valós, sokasági értékét. Azonban, a **hipotézisvizsgálat gondolatvilága a kérdést némileg eltérően közelíti meg, mint az eddig tanult konfidencia-intervallumok**.

Hipotézisvizsgálat során megfogalmazunk egy **állítást vagy szebb szóval hipotézist egy statisztikai mutatószám** (átlag, arány, medián, szórás, stb.) **valós, sokasági értékéről, és utána megpróbáljuk állítani, hogy ezt a felvetést/hipotézist a megfigyelt mintaadatok alátámasztják-e vagy sem**. Most így alapesetben a paraméteres statisztikai hipotézisvizsgálatokat vagy rövidebben az úgynevezett **paraméteres (statisztikai) próbákat vizsgáljuk**, mert a **megfogalmazott hipotézisünk mindig egy statisztikai paraméter** (azaz statisztikai mutatószám) valós, **sokasági értékéről szól** majd egyelőre.

Nézzünk meg **ismét egy $n=100$ elemű FAE mintát a 2022-es Balaton átúszást teljesítők sokaságából** a <a href="https://github.com/KoLa992/Statistical-Modelling-Lecture-Notes/blob/main/LIDLBalaton2022.xlsx" target="_blank">LIDLBalaton2022.xlsx</a> fájl alapján.<br>
Ahogy a <a href="Chapter05.html" target="_blank">Chapter 5</a>-ben is néztük, ebben a fájlban a Balaton átúszás résztvevőinek *neve, neme és percben mért időeredménye* található. Ez az adatsor lesz most is a **sokaságunk**.

```{r}
library(readxl)

# Adatbeolvasás data frame-be
swimming_population <- read_excel("LIDLBalaton2022.xlsx")
str(swimming_population)
```

Szuper, vegyük is ki azt az $n=100$ elemű FAE mintát! Rögzítsük meg a `set.seed`-ben  az értéket $1992$-nek, hogy mindannyian ugyan azt a $100$ elemű véletlen mintát kapjuk!

```{r}
set.seed(1992)
selected_into_sample <- sample(rownames(swimming_population), size = 100, replace = TRUE)
swimming_sample <- swimming_population[selected_into_sample,]
str(swimming_sample)
```

Namármost. A **teljes sokaság átlagos átúszási idejéről $6$ db különböző állítást tudok megfogalmazni** egy konkrét érték, pl. az $2.5$ óra, azaz $150$perc viszonylatában. A valós, sokasági átlagos időeredményt most is $\mu$-vel jelöljük:

1. Optimista vagyok, és azt mondom, hogy gyorsak voltak a népek és az átlagos átúszási idő a sokaságban kisebb, mint $150$ perc: $\mu < 150$
2. Pesszimista magyarként azt is mondhatom, hogy lassú volt az úszótömeg és az átlagos időeredmény a sokaságban nagyobb, mint $150$ perc: $\mu > 150$
3. De még azt is el tudom képzelni, hogy a valós átlag úszási idő épp $150$ perc: $\mu = 150$
4. Vagy abban is hihetek, hogy a sokaságban az átlag időeredmény minden csak nem $150$ perc: $\mu \neq 150$
5. A *félig optimista* mondhatja azt, hogy a sokasági átlagos időeredmény *legfeljebb* $150$ perc: $\mu \leq 150$
6. Kizárásos alapon a *félig pesszimista* pedig úgy fog vélekedni, hogy a sokasági átlagos úszási idő *legalább* $150$ perc: $\mu \geq 150$

Oké, akkor van $6$ db elméletem...azaz *hipotézis*em. Nézzük meg mennyi az **átlag a megfigyelt $100$ elemű mintában**:

```{r}
mean(swimming_sample$TIME)
```

No, a megfigyelt $100$ átúszó alapján a mintaátlag kb. $161$ perc. Ez alapján a 2. állítás, a pesszimista ürge mondása tűnik igaznak, az **átlag nagyobb, mint** $150$ perc. NODE! **Amit itt látunk az csak $100$ ember átlagos ideje, a teljes sokaságban az átlagos átúszási idő ettől eltérhet!**<br>
Szebben fogalmazva, **a $161$ és $150$ közti különbség simán betudható a mintavételi hibának is!!**<br>
**Ezért végzünk hipotézisvizsgálatot**, hogy eldöntsük, hogy a $\mu > 150$ hipotézis (állítás) igaznak vehető-e még a mintavételi hibával együtt is.

Igazából, ha belegondolunk, akkor mind a $6$ állítás visszavezethető ahhoz a kérdéshez, hogy a valós, sokasági átlag, $\mu$ **eltér-e** annyira a $150$-től, hogy az **eltérés már meghaladja a mintavételi hibát**. Ezt úgy mondjuk szépen, hogy **azt vizsgáljuk, SZIGNIFIKÁNS-e az eltérés a valós $\mu$ és $150$ között!**

Most itt éppen ki tudjuk számolni a teljes sokaság ismeretében, hogy $\mu=167$ perc, ami **tényleg magasabb, mint** $150$.

```{r}
mean(swimming_population$TIME)
```

A **gyakorlatban viszont mindezt NEM tudjatjuk, hiszen csak az $n=100$ elemű minta áll rendelkezésünkre!!** Szóval **marad az, hogy hipotézisvizsgálattal ellenőrizzük, hogy a $\bar{y}=161$ megfigyelt mintaátlag szignifikánsan eltér-e a $150$-től**.

Az eddigi logikánk alapján létre tudunk hozni egy úgynevezett **nullhipotézist** ($H_0$) és **alternatyv hipotézist** ($H_1$) az **eredeti állításunkból**.

A pontos logika itt a következő. A $H_0$-ban mindig olyan állítást fogalmazunk meg, ami **a vizsgált statisztikai paraméter tekintetében megengedi az egyenlőséget**.<br>
A $H_1$ pedig az **eredeti állítástól függ**:

- Ha az **eredeti állítás megengedi az egyenlőséget**, akkor az állítás $H_0$-ba kerül és **a $H_1$-ben tagadjuk az eredeti állítást**. Ebből adódóan azt várjuk, hogy a hipotézisvizsgálat végén **a $H_0$ állítás bizonyuljon igaznak**. Ebben az esetben azt szeretnénk, hogy **a valós sokasági átlag átúszási idő ne különbözzön szignifikánsan a $150$ perctől**.
- Ha az **eredeti állítás nem engedi meg az egyenlőséget**, akkor az a $H_1$-be "költözik", és **a $H_0$-ban az eredeti állítást tagadjuk**. Ebből adódóan azt várjuk, hogy a hipotézisvizsgálat végén **a $H_1$ állítás bizonyuljon igaznak**. Ebben az esetben azt szeretnénk, hogy **a valós sokasági átlag átúszási idő szignifikánsan különbözzön a $150$ perctől**.

Ezen elveket figyelembe véve a $6$ eredeti állításunkhoz a következő $H_0$ és $H_1$ párok adhatók meg:

1. Állítás: $\mu < 150$ || $H_0:\mu \geq 150$ || $H_1:\mu < 150$ || Állítás a $H_1$-ben található.
2. Állítás: $\mu > 150$ || $H_0:\mu \leq 150$ || $H_1:\mu > 150$ || Állítás a $H_1$-ben található.
3. Állítás: $\mu = 150$ || $H_0:\mu = 150$ || $H_1:\mu \neq 150$ || Állítás a $H_0$-ban található.
4. Állítás: $\mu \neq 150$ || $H_0:\mu = 150$ || $H_1:\mu \neq 150$ || Állítás a $H_1$-ben található.
5. Állítás: $\mu \leq 150$ || $H_0:\mu \leq 150$ || $H_1:\mu > 150$ || Állítás a $H_0$-ban található.
6. Állítás: $\mu \geq 150$ || $H_0:\mu \geq 150$ || $H_1:\mu < 150$ || Állítás a $H_0$-ban található.

Az 1-2. és 5-6 állításokban, ahol **nem "tiszta" egyenlőség van $H_0$-ban szoktunk úgynevezett technikai nullhipotézist, $H_0^T$-t alkalmazni**. Ez csak annyit jelent, hogy a **nem "tiszta" egyenlőséggel adott $H_0$-t átírjuk tiszta egyenlőségre**.<br>
Tehát, pl. az **1. és 5. állítás technikai nullhipotézissel**:

1. Állítás: $\mu < 150$ || $H_0^T:\mu = 150$ || $H_1:\mu < 150$ || Állítás a $H_1$-ben található.
5. Állítás: $\mu \leq 150$ || $H_0^T:\mu = 150$ || $H_1:\mu > 150$ || Állítás a $H_0$-ban található.

A hipotézisvizsgákat vagy más néven **statisztikai próbákat a $H_1$-ben adott relációs jeleik alapján három csoportba kategórizálják**:

- Ha $H_1$-ben $\neq$ jel van, akkor **kétoldali próba**
- Ha $H_1$-ben $<$ jel van, akkor **baloldali próba**
- Ha $H_1$-ben $>$ jel van, akkor **jobboldali próba**

### 1.1. A p-érték fogalma

Ha szépen felírtuk a megfelelő $H_0$ és $H_1$ párokat, akkor meghatározzuk, hogy a megfigyelt mintánk alapjánk melyik tekinthető igaznak a kettő közül. Erre a célra egy **p-érték nevű statisztikai mutatószámot használunk**. A **p-érték megadja, hogy a $H_0$ állítást IGAZnak feltételezve mekkora a valószínűsége, hogy a megfigyelt mintaadataimnál NAGYOBB eltérést kapok $H_0$-tól**. Tehát, nyilvánvalóan a mintából számított statisztikai mutató értéke sosem lesz egyenlő azzal, amit $H_0$-ban állítottam. A kérdés az, hogy **mekkora a valószínűsége, hogy egy random másik mintából nagyobb eltérést kapok a $H_0$-hoz képest, mint amit a jelenlegi mintából megfigyeltem**. Ezt a valószínűséget fejezi ki ez a **p-érték** nevű cucc: $$P(OtherRandomDifference>MyDifference|H_0)$$

Szóval, ha azt kapom, hogy pl. **p-érték = 30%**, akkor azt mondhatom, hogy **30% valószínűséggel kapok nagyobb eltérést egy másik mintában a $H_0$-hoz képest, mint amit a saját adataimban megfigyeltem**. Ez alapján hajlok arra, hogy elfogadjam $H_0$-at, mert ha azt igaznak veszem, akkor elég nagy valószínűséggel kapok még nagyobb eltéréseket $H_0$-tól más random mintákban, mint amit én megfigyeltem. Szóval, **az általam megfigyelt eltérés nem elég nagy a $H_0$-hoz képest (nem szignifikáns), így inkább nem utasítom azt el, mert az adataim nem szolgáltatnak ehhez a döntéshez elég bizonyítékot**.

Ellenben, ha azt kapom, hogy pl. **p-érték = 0.1%**, akkor azt mondhatom, hogy **csak 0.1% valószínűséggel kapok nagyobb eltérést egy másik mintában a $H_0$-hoz képest, mint amit a saját adataimban megfigyeltem**. Ez alapján hajlok arra, hogy elutasítsam $H_0$-at, mert ebben az esetben $H_0$-t igaznak véve csak kis valószínűséggel kapok nagyobb eltérést $H_0$-tól, mint amit megfigyeltem. Tehát, **az általam megfigyelt eltérés a $H_0$-hoz képest elég nagy (szignifikáns), így bátran elutasítom, mert az adataim elég bizonyítékot szolgáltatnak ehhez a döntéshez**.

Midnezek alapján a **döntési szabály** $H_0$ és $H_1$ között a következő. Amennyiben a **p-érték túl magas, elfogadjuk** $H_0$-t, mivel elutasítása túl nagy hibavalószínűséggel járna. Ellenben ha a **p-érték túl alacsony**, akkor elutasítjuk $H_0$-t és **elfogadjuk** $H_1$**-et**.

A kérdés az hogyan döntöm el, hogy egy p-érték túl magas/alacsony-e? Erre van nekünk az úgynevezett **szignifikancia-szint, amit** $\alpha$**-val jelölünk**. A szignifikancia-szint a **maximális elfogadott hibavalószínűség $H_0$ elutasításához**.

Tehát, ha azt mondjuk, hogy $\alpha=5\%$, akkor $5\%$ alatti p-érték esetén **elutasítjuk $H_0$-t, mert a megfigyelt adatok elég nagy eltérést mutatnak $H_0$-tól, hogy az elutasítással biztosítani tudjak egy maximum $5\%$ hibavalószínűséget**. Másrészről, ha a p-értékünk $5\%$ feletti, akkor meg **elfogadjuk $H_0$-t, a megfigyelt adatok NEM mutatnak elég nagy eltérést $H_0$-tól, hogy az elutasítással biztosítani tudjak egy maximum $5\%$ hibavalószínűséget**.

Ezen a ponton tehát a **következőt hinnénk**:

- **p-érték** $>\alpha \rightarrow H_0$
- **p-érték** $\leq\alpha \rightarrow H_1$

De természetesen **AZ ÉLET SOSEM ILYEN EGYSZERŰ!!** a fő probléma itt abból jön, hogy **simán lehetnek olyan mintaadataink, hogy a meghozott döntés marhára függ attól mit mondok pontosan $\alpha$-nak!** Pl. oké, maximum megenegedett hibavalószínűségem $\alpha=5\%$. A p-értékre meg kapok egy $4.8\%$-ot. Na akkor $\alpha=5\%$ esetén elutasítanánk $H_0$-t, de egy $\alpha=3\%$-nál már épp elutasítanánk $H_0$-t.<br>
Emiatt alkalmazzuk a **szokásos szignifikancia-szintek tartományát, ami $1\%-10\%$ között mozog**. Nem akarunk $10\%$-nál nagyobb megenegedett $\alpha$ hibát, mert az már tényleg magas hibavalószínűség. Másrészről meg $0\%$ **hibavalószínűségünk meg csak úgy lehet, ha megfigyeljük az egész sokaságot, és tudjuk mennyi a vizsgált statisztikai paraméter valós, sokasági értéke**. Ekkor meg pont a mintavétel lényegét veszítjük el, hogy nem kell megfigyelni minden múltbeli és jövőbeli adatpontot ahhoz, hogy dönteni tudjunk a vizsgált mutatószámunk valós, sokasági értékéről. Ez utóbbi $\alpha=0\%$ eset hasonló ahhoz, amikor azt mondtuk, hogy a $100\%$ megbízhatóságú konfidencia-intervallumnak sincs semmi értelme, mert akkor azt mondanánk, hogy a mintavételünk alapján a vizsgált statisztikai mutatószámunk (paraméterünk) bárho lehet $\pm\infty$ között... :)<br>
Továbbá, majd **szimulációkból látni fogjuk, hogy $1\%$ és $10\%$ közti p-értéket simán produkál a valóságban igaz és hamis $H_0$ állítás is**!

Szóval, az előbbi családregényünk alapján az tűnik egy normálisabb megoldásnak, ha **azt mondjuk, hogy $1\%$ és $10\%$ közti p-érték esetén nem választunk $H_0$ és $H_1$ között, mert ekkor a döntésünk nagyon érzékeny lenne a konkrét $\alpha$ megválasztására**<br>
Ha egy $1\%$ és $10\%$ közti p-értéket produkálnak a mintaadataink, akkor a legjobb, amit tehetünk, hogy **addig növeljük a mintaméretet ($n$-t) amíg a p-érték egyértelműen $1\%$ alá vagy $10\%$ fölé nem kerül**. Ezt a módszert hívja a statisztika <a href="https://en.wikipedia.org/wiki/Sequential_analysis" target="_blank">szekvenciális analízisnek</a>, és a klinikai gyógyszerkísérletekben és az ipari minőségbiztosításban rendszeresen alkalmazzák. A módszer alapjait pedig egy <a href="https://en.wikipedia.org/wiki/Abraham_Wald" target="_blank">Abraham Wald</a> nevű magar statisztikus dolgozta ki az Amerikai Légierőnek a II. világháború alatt (zsidó származása miatt itthon "nem kellett"). Szóval, mint minden fontos területet a világon, ezt is magyarok találták ki. :)

Tehát, az egy fokkal **korrektebb döntés szabályok hipotézisvizsgálat esetén**:

- **p-érték** $>10\% \rightarrow H_0$
- $1\% <$ **p-érték** $\leq 10\% \rightarrow$ **nincs döntés**
- **p-érték** $\leq1\% \rightarrow H_1$

További fejfájásokat okoz, hogy nagyon óvatosan kell bánni az $1\%$ és $10\%$ közti p-értékkel azért is, mert a **p-érték és az $\alpha$ csak egy nézőpontból írják le a hipotézisvizsgálat során elkövethető döntési hibát**! A **p-érték és az $\alpha$ csak az úgyenevzett ELSŐFAJÚ hibáról ad információt: a valóságban igaz $H_0$ elutasításának valószínűségéről**!<br>
NODE, van nekünk **MÁSODFAJÚ hibánk is**, ami a **valóságban hamis $H_0$ téves elfoggadását jelenti**. Az a rossz hír, hogy ennek a **másodfajú hibának a valószínűségét nem tudjuk megbecsülni és befolyásolni a megfigyelt minta alapján!!**<br>
Ez a hipotézoisvizsgálat nagy átka: ha **elfogadunk egy $H_0$-t, akkor igazából nem tudjuk, hogy mekkora valószínűséggel hibázunk, csak azt tudjuk, hogy mennyi a $H_0$ elutasításának maximális hibavalószínűsége, mert ez pont a szignifikancia szint**.<br>
Ezért nagyon sokan fogalmaznak szándékosan ilyen furán a $H_0$-ról, hogy nem elfogadjuk a $H_0$-t, hanem **nem tudjuk elutasítani a $H_0$-t**.

A probléma alaposabb megértésében szerintem remek szolgálatot tesz az alábbi mém. :)

<center>
![](Type2.png){width=40%}
</center>

<br>Most pedig nézzük meg **hogyan kell kiszámolni a p-értéket a megfigyelt minta alapján abban az esetben, amikor a vizsgált statisztikai paraméter az átlag**, azaz $\mu$!

## 2. A sokasági átlagra vonatkozó *t-próba*

A p-érték számításához **mindig szükségünk van egy próbafüggvény nevű statisztikai mutatóra, amit csak a megfigyelt mintaadatokból ki tudunk mindig számolni**. Eztán a **p-értéket a próbafüggvényből egy nevezetes valószínűségi eloszlás (standard normális, t-eloszlás, khi-négyzet, stb.) alapján tudjuk kiszámolni**.

Jelöljük a **sokasági átlag HIPOTETIKUS értékét** $\mu_0$-nak. Ez az érték, amit az állításban **feltételezek** a valós, sokasági átlagról. Az 1. fejezetben ez volt a $150$ perc. Ezzel a jelöléssel az alábbi módon néz ki az átlagra vonatkozó próbafüggvény: $$\frac{\bar{y}-\mu_0}{\frac{s}{\sqrt{n}}}$$

Tehát, a próbafüggvényünk most nem más, mint a **minta és hipotetikus átlag különbsége osztva az átlag standard hibájával**.

Ha a $H_0$-ban jól okoskodunk, és **tényleg sikerült a valós $\mu$ sokasági átlagot venni a $\mu_0$ elvi** (hipotetikus) **átlagnak, akkor sok-sok mintavétel esetén a próbafüggvényünk $n-1$ szabadságfokú t-eloszlást követ**: $$\frac{\bar{y}-\mu}{\frac{s}{\sqrt{n}}} \sim t(n-1)$$

A képlet mögött az az elv nyugszik, hogy **a $\mu = \mu_0$ technikai nullhipotézist ($H_0^T$) alkalmazzuk mind a 6 különböző típusú $H_0$ és $H_1$ párosnál, így meg tudjuk majd adni a próbafüggvény eloszlását sok-sok mintavétel esetén**.

Ezt az egészet gyorsan ellenőrizni tudjuk, ha **kiveszünk $10000$ db $n=100$ elemű FAE mintát a Balaton átúszók sokaságából**, ahogy a <a href="Chapter05.html" target="_blank">Chapter 5</a>-ben is tettük.<br>
Most csak **visszatöltjük a $10000$ db FAE mintát tartalmazó Excel táblát egy data frame-be**, amit a <a href="Chapter04.html" target="_blank">Chapter 4</a>-ben hoztunk létre. Ez az Excel fájl <a href="https://github.com/KoLa992/Statistical-Modelling-Lecture-Notes/blob/main/SwimmingSamples.xlsx" target="_blank">innen</a> elérhető.

```{r}
samples_100 <- as.data.frame(read_excel("SwimmingSamples.xlsx"))
rownames(samples_100) <- paste0("Sample",1:10000) # indicate in the rownames that each row is one sample
head(samples_100)
```

Oké, az eredményből látjuk is, hogy úgy néz ki a data frame, hogy **1 sor tartalmaz 1 db 100 elemű mintát és a mintaelemeket** (tehát a mintába besorsolt versenyző percben mért időeredményét) **az oszlopkban tároljuk**.

Kiszámoljuk mindenegyes mintavételre a minta átlagos időeredményét és azok korrigált szórását. Csak figyeljünk, hogy az alkalmazott `sapply` függvények második paramétere `1` legyen, hogy ne oszlopok, hanem sorok szerint vegyük az átlagokat és a szórásokat. Plusz, figyeljünk, hogy a függvényeket minidg csak az első $100$ oszlopra engedjük rá, hiszen ott vannak a tényleges mintaelemek. Pontosan úgy csináljunk mindent tehát, ahogy a <a href="Chapter05.html" target="_blank">Section 2 of Chapter 5</a>-ben tettük.

```{r}
samples_100$sample_mean <- apply(samples_100[,1:100], 1, mean)
samples_100$sample_sd <- apply(samples_100[,1:100], 1, sd) # corrected -> unbiased

head(samples_100[,97:102])
```

Ezek után pedig **ki tudjuk számolni a próbafüggvényünket egy olyan $H_0$ és $H_1$ párosra, amiről tudjuk, hogy a sokaságban $H_0$ igaz, és egy olyanra, ahol tudjuk, hogy a sokaságban $H_0$ hamis**:

- **IGAZ** $H_0$ esete: $H_0:\mu=167$ és $H_1: \mu < 167$
- **HAMIS** $H_0$ esete: $H_0^T:\mu=150$ és $H_1: \mu > 150$

```{r}
mu_0_true <- mean(swimming_population$TIME) # true population mean
mu_0_false <- 150 # arbitrary value
n <- 100 # sample size

samples_100$test_stat_H0true <- (samples_100$sample_mean - mu_0_true)/(samples_100$sample_sd/sqrt(n))
samples_100$test_stat_H0false <- (samples_100$sample_mean - mu_0_false)/(samples_100$sample_sd/sqrt(n))

head(samples_100[,99:104])
```

Okké! Akkor miután megvannak a kétféle esetben a próbafüggvényeink, **nézzük meg a kétféle próbafüggvények hisztogramja a $10000$ db mintavétel alapján hogyan alakul a $t(n-1)$, azaz $t(100-1)$ eloszlás sűrűségfüggvényéhez** képest.<br>
A sűrűségfüggvény hisztogramhoz való illeszkedését ábrázoló kód teljes mértékben az <a href="Chapter03.html" target="_blank">Section 1.3. of Chapter 3</a>-ben lévő kódok logikáját követi.

```{r warning=FALSE}
library(ggplot2)

# general ggplot function without defining any axes
ggplot(samples_100) +
  # histogram of test statistic when H0 is TRUE (x axis)
  geom_histogram(aes(x = test_stat_H0true, y = after_stat(density), fill="H0 TRUE")) +
  # histogram of test statistic when H0 is FALSE (x axis)
  geom_histogram(aes(x = test_stat_H0false, y = after_stat(density), fill="H0 FALSE")) +
  # adding the density function of the t(n-1) distribution
  stat_function(fun = dt, 
                args = list(df = (n-1)),
                col = 'blue', linewidth = 1)
```

Szuper! Tehát **igaz $H_0$ esetén tényleg t-eloszlást követ a próbafüggvény a sok-sok mintavételünk esetén**. Hamis $H_0$ esetén pedig valami más szimmetrikus eloszlás rajzolódik ki a hisztogramon, ami NEM a t-eloszlás. De hogy ez most konkrétan mi, nem annyira érdekel minket. :)

Ebből, hogy a próbafüggvény t-eloszlást követ sok-sok mintavétel esetén, ha $H_0$ igaz, **ki tudjuk számolni a p-értéket**. gyakorlatilag területeket számolunk a *t-eloszlás* sűrűségfüggvénye alatt. A konkrét számoláshoz végig kell gondolnunk, hogy **mi a legjobb eset $H_0$ szempontjából a próbafüggvényre nézve**:

- **Kétoldali** próbák ($H_0: \mu=\mu_0$ és $H_1: \mu \neq \mu_0$) esetén: ha a **próbafüggvény pontosan** $0 \rightarrow$ ez az elvi eset arra utal, hogy a hipotetikus átlag és a valós, sokasági átlag ugyanaz, így $1$ valószínűséggel kaphatok más mintákban nagyobb eltéréseket $H_0$-tól, mint amit ekkor megfigyeltem.
- **Baloldali** próbák ($H_0: \mu\geq\mu_0$ és $H_1: \mu < \mu_0$) esetén: ha a **próbafüggvény =** $+\infty \rightarrow$ ez az elvi eset arra utal, hogy a sokasági átlag ($\mu$) az pont $+\infty$, aminél minden $\mu_0$ kisebb, így $1$ valószínűséggel kaphatok más mintákban nagyobb eltéréseket $H_0$-tól, mint amit ekkor megfigyeltem.
- **Jobboldali** próbák ($H_0: \mu=\mu_0$ és $H_1: \mu > \mu_0$) esetén: ha a **próbafüggvény =** $-\infty \rightarrow$ ez az elvi eset arra utal, hogy a sokasági átlag ($\mu$) az pont $-\infty$, aminél minden $\mu_0$ nagyobb, így $1$ valószínűséggel kaphatok más mintákban nagyobb eltéréseket $H_0$-tól, mint amit ekkor megfigyeltem.

Ez alapján,ha **van egy ismert próbafüggvény értékem, amit $t$-vel jelölök, akkor a p-érték a $t(n-1)$ eloszlásból az alábbi ábrán látható módon számítható ki**:

<center>
![](pval_fromt.jpg){width=90%}
</center>

<br>Látható, hogy **mindhárom esetben a p-érték úgy lesz kiszámolva, hogy ha a konkrét $t$ próbafüggvényünk messzebb kerül a $H_0$ számára legjobb esettől, akkor a p-érték csökken $\rightarrow$ hiszen egyre kisebb és kisebb valószínűséggel kaphatok a megfigyeltnél nagyobb eltéréseket $H_0$-tól!!**

Mindezek alapján akkor **számoljuk ki** a `pt` függvény segítségével a **p-értéket mind a $10000$ db mintában a korábban vizsgált két $H_0$ és $H_1$ párunkra, ahol egyszer igaz, egyszer pedig hamis volt a** $H_0$:

- **IGAZ** $H_0$ esete: $H_0:\mu=167$ és $H_1: \mu < 167$
- **HAMIS** $H_0$ esete: $H_0:\mu=150$ és $H_1: \mu > 150$

Figyeljünk arra, hogy az $1-$ rész a `pt` függvényen a hamis $H_0$ esetben a **jobboldali próba** miatt van:

```{r}
samples_100$p_value_H0true <- pt(samples_100$test_stat_H0true, df = (n-1))
samples_100$p_value_H0false <- 1-pt(samples_100$test_stat_H0false, df = (n-1))

head(samples_100[,101:106])
```

Remek! Az első $6$ db minta alapján az elvárt eredményeket kaptuk a p-értékekre: magas értékek igaz $H_0$, alacsony értékek hamis $H_0$ esetén. Pontosabb értelmezéshez nézzük meg **az $4.$ minta esetét**:

- **Igaz $H_0$ esetén $69.78\%$-os valószínűséggel kapunk nagyobb eltéréseket $H_0$-tól, mint amit a 4. mintában megfigyeltünk**.
- **Hamis $H_0$ esetén csak $0.01\%$-os valószínűséggel kapunk nagyobb eltéréseket $H_0$-tól, mint amit a 4. mintában megfigyeltünk**.

Ugyanakkor az $1.$ mintában látjuk, hogy a p-érték csak $3.5\%$ igaz $H_0$ esetén. Szóval, a **"nem hozunk döntést, ha a p-érték $1\% - 10\%$ között mozog", egy elég jogos szabálynak tűnik**! :)

Hasonlóan megerősíti az $1\% - 10\%$ közötti p-értékek esetén vett óvatosságot, ha  az igaz és hamis $H_0$ esetén vizsgált p-értékeket doboz ábrán vizsgáljuk:

```{r}
boxplot(samples_100[,c("p_value_H0true", "p_value_H0false")])
```

Ahogyan vártuk is, igaz $H_0$ esetén a p-értékek középső $50\%$-a, azaz interkavrtilis trejedelme ($IQR$) látványosan magasabban van, mint hamis $H_0$ esetében. Ugyanakkor, azt is nagyon fontos látni az ábrán, hogy **a nagy p-értékek kilógó értéknek számítanak hamis $H_0$ esetén, de a kis p-értékek nem kilógó értékek igaz $H_0$ esetében!** Tehát, néha megérheto szigorúbb $\alpha$-t használni, mint $1\%$. Sokan csak akkor utasítják el $H_0$-t, ha a p-érték kisebb, mint $0.1\%=0.001$, szóval $\alpha=0.001$ mellett dolgoznak.

Az eredményeink alapján kiszámolhatjuk a döntési hibák arányát $\alpha=5\%$ mellett igaz $H_0$ esetén. Tehát, az **elsőfajú hiba empirikus valószínűsége** lesz ez: mekkora arányban utasítottunk el valóságban igaz $H_0$-t! Ugye a szignifikancia-szint definíciója alapján ennek az aránynak $5\%$ körül kéne lennie.

```{r}
mean(samples_100$p_value_H0true<0.05)
```

Hát az eredmény $6.05\%$, 1 százalékponttal nagyobb, mint $5\%$, de nem sokkal. Nagyjából úgy néz ki, hogy a rendszer működik. Ha még több mintát vizsgálnánk, mint 10000, akkor ez az arány egyre közelebb fog kerülni az $5\%$-hoz.

Sőt, mivel most tudjuk, hogy mikor igaz és hamis $H_0$, ki tudjuk most számolni a **másodfajú hiba empirikus valószínűségét** is $\alpha=5\%$ mellett: mekkora arányban fogadjuk el a valóságban hamis $H_0$-t.

```{r}
mean(samples_100$p_value_H0false>=0.05)
```

Egész jó, $0.52\%$!

Figyeljük meg azt a teljesen logikus összefüggést, hogy ha az **elsőfajú hibavalószínűsége (szignifikancia-szint) csökken, akkor a másodfajú hiba valószínásége nő**. Számoljuk ki akkor hát a két empirikus hibavalószínűséget $\alpha=1\%$ mellett. Tehát, az elsőfajú hiba elvárt valószínűségét levittük $1\%$-ra.

```{r}
mean(samples_100$p_value_H0true<0.01) # empirical probability of Type I error
mean(samples_100$p_value_H0false>=0.01) # empirical probability of Type II error
```

### 2.1. A *t-próba* beépített függvénnyel

Azért van némi szerencsénk, mert az **átlagra vonatkozó t-próba p-értékét szépen ki lehet számolni beépített R függvénnyel** is!

Vegyük például a Section 1 elején kivett $n=100$ elemű mintát, amit a `swimming_sample` című R objektumban tároltunk le, ami egy $100\times3$-as data frame:

```{r}
str(swimming_sample)
```

Vizsgáljuk meg ezen a mintán az alábbi $H_0$ és $H_1$ párost:

- $H_0^T:\mu=150$
- $H_1 > 150$

Mivel $H_1$-ben $>$ relációs jel lakik, így **jobboldali** lesz a hipotézisvizsgálat.<br>
Tudjuk, hogy itt **a $H_1$ lesz igaz, hiszen láttuk korábban, hogy a teljes sokaságban az átlagos átúszási idő $167.5$ perc**. Tehát, valami **jó alacsony p-értéket várunk**!

Ez szépen ki is jön manuálisan is! Először kiszámoljuk a $\frac{\bar{y}-\mu_0}{\frac{s}{\sqrt{n}}}$ **próbafüggvényt** $\mu_0=150$ mellett, hiszen a hipotézisekben azt nézzük, hogy a valós, sokasági átlag szignifikánsan nagyobb-e, mint ez a feltételezett (hipotetikus) $150$ perces átlag.

```{r}
hypothetical_mean <- 150
sample_mean <- mean(swimming_sample$TIME)
s <- sd(swimming_sample$TIME)
n <- nrow(swimming_sample)

test_stat <- (sample_mean - hypothetical_mean) / (s/sqrt(n))
test_stat
```

Remek! Ebből gyorsan is meg is van a $t(n-1)$ eloszlásból (`pt` függvénnyel) a p-érték. Most ugye a **próbafüggvény felé esés valószínűségét számoljuk, hiszen jobboldali a próba**.

```{r}
p_val_t_distr = 1 - pt(test_stat, df = n-1)
p_val_t_distr * 100 # in percentage format
```

A **p-érték alapján elmonható, hogy a most vizsgált $100$ elemű minta alapján csak $0.203\%$ a valószínűsége annak, hogy egy másik mintában az itt megfigyeltnél nagyobb eltérést találunk $H_0$-hoz képest**. Ez **kisebb még a legkisebb szokásos szignifikancia-szintnél, az $\alpha=1\%$-nál is, így meghozzuk azt a döntést és $H_0$-t elutasítjuk**.<br>
Ez alapján pedig $H_1$ elfogadható, azaz a **sokaságban az átlagos átúszási idő szignifikánsan** (mintavételi hibát meghaladó mértékben) **nagyobb, mint $150$ perc**.<br>
Most tudjuk, hogy **helyesen döntöttünk**, mivel láttuk, hogy a sokaságban az átlagos átúszási idő $167.5$ perc.

Mindez szerencsére elintézhető a `t.test` függvényével is. Ha a függvény

- első paraméterében megadjuk az aktuális mintánk elemeit tartalmazó oszlopot egy data frame-ből,
- a `mu` paraméterben az elvi átlagot, azaz $\mu_0$-t,
- az `alternative` paraméterben pedig a próba oldalát $H_1$ relációs jele alapján
  * lehetséges értékek: `‘two.sided’, ‘less’, ‘greater’`, rendre a $\neq$, $<$, $>$ relációs jeleket jelölik $H_1$-ben

Akkor a **függvény megadja a t-próba p-értékét és a próbafüggvényt is**:

```{r}
t.test(swimming_sample$TIME, mu = 150, alternative = "greater")
```

Szuper, ugyan úgy megvan a próbafüggvény ($2.9416$) és a $0.2033\%$-os p-érték is! :)

### 2.2. A *t-próba* előfeltételei

Természetesen, ennek a t-próbás hipotézisvizsgálatnak is vannak előfeltételei, mint ahogy a különböző konfidencia-intervallum képleteknek is voltak. **Ha ezek a feltételek nem teljesülnek, akkor bármi is jött ki p-értékre, azt nem használhatjuk döntésre $H_0$-ról és $H_1$-ről**, hiszen az alkalmazott képletek mögötti követelmények az adatokal szemben NEM teljesülnek.

A t-próbának alapvetően **két feltétel**ére kell odafigyelni:

1. Amennyiben **kis mintánk** ($n<100$) van, akkor feltesszük, hogy **az adatok, amikből a mintát vettük normális eloszlást követnek**
2. Ha a **minta elemszáma nagy** ($n\geq100$), akkor **nem kell semmi extra előfeltételre figyelni**.

Most az $n=100$ elemű mintánk a Balaton átúszók sokaságából már épp nagy minta, hiszen $100\geq100$, de azért nézzünk rá az **időeredmény adatok eloszlására a minta alapján**:

```{r}
hist(swimming_sample$TIME)
```

Hm, bár a nagy mintaelemszám miatt ez nem számít, de azért megnyugtató, hogy az átúszási idők eloszlása nem olyan durván tér el a normális eloszlás sűrűségfüggvényétől. Csak nagyon enyhén van egy kis jobbra elnyúló jellege, de semmi vészes. :)

## 3. A sokasági átlagra vonatkozó *z-próba*

Ugyebár az átlagra vonatkozó konfidencia-intervallumok esetén megfigyeltük, hogy **nagy szabadságfok ($df\geq100$) esetén a t-eloszlás lényegében megegyezik a standard normális eloszlással**.

Azaz, kicsit matekosabban fogalmazva: **ha $n \geq100$, akkor igaz nullhipotézis ($H_0$) esetén** (tehát, amikor $\mu_0$ helyére épp a valós, sokasági átlagot, azaz $\mu$-t helyettesítjük), a **próbafüggvényünk standard normális ($N(0,1)$) eloszlást követ**: $$\frac{\bar{y}-\mu}{\frac{s}{\sqrt{n}}} \sim N(0,1)$$

Ez alapján pontosan **ugyan azon az elven számíthatunk a próbafüggvényből p-értéket, amit a 2. fejezetben a t-eloszlásnál is alkalmaztunk**. Mivel a null-és alternatív hipotézis nem változott meg ($H_0^T:\mu=150$ és $H_1 > 150$), így marad a jobboldali próba, és mivel a mintaelemek sem változtak a 100 elemű mintánkban, így a **próbafüggvény is megegyezik a 2.1. fejezetben használttal**.<br>
**Mivel maradt a jobboldali próba**, így a **próbafüggvény fölé esés valószínűségét kell megadni a standard normális eloszlásban** a `pnorm` függvény $1-$ verziójával.

```{r}
p_val_norm_distr <- 1 - pnorm(test_stat)
p_val_norm_distr * 100 # percentage format

p_val_t_distr * 100 # p-value from t-distribution in percentage format
```

Mindkét p-érték nagyjából $0.2\%$ körüli, szóval a standard normális és t-eloszlás között tényleg nincs érdemi különbség a p-érték számolás tekintetében.

## 4. A sokasági arányra vonatkozó *z-próba*

Természetesen, nem csak sokasági átlagokra ($\mu$), hanem sokasági arányokra ($P$) is tudunk hipotéziseket tenni. Majd ehhez is tudunk p-értéket számolni és eldönteni, hogy az eredeti állításunkból felírt $H_0$ vagy $H_1$ tekinthető-e igaznak egy adott $\alpha$ szignifikancia-szinten.

Nézzük meg, hogy **vehető-e 30%-nak a Balatont 3 óra felett átúszók aránya**. Matematikailag az állításom azt mondja, hogy a 3 óra = 180 perc felett átúszók sokasági aránya egyenlő épp 30%: $P = 0.3$. Mivel az **állítás engedi az egyenlőséget, így az a $H_0$-ba kerül**. Ez alapján pedig **a $H_1$-ben az eredeti állítást tagadjuk, és a $H_0$-nak szurkolunk** a hipotézisvizsgálat során. Tehát, a $H_0$ és $H_1$ párunk az alábbi módra fog kinézni:

- $H_0:P=0.3$
- $H_1:P\neq0.3$
- Szurkolunk: $H_0$

A $H_0$ és $H_1$ párunkból következik, hogy az **elvi arány, azaz $P_0$, amihez képest vizgsálódunk most az $0.3$ érték!!**

Ezek után itt most azt mondanánk <a href="Chapter08.html" target="_blank">Section 2 of Chapter 8</a> alapján, hogy készítünk a megfigyelt mintánkba egy olyan $0-1$ értékekből álló oszlopot, ahol $1$ jelenti a 3 óránál hosszabb idő alatt átúszókat a mintában (arány szempontjából kedvező esetek a mintában), míg $0$ a többieket (arány szempontjából kedvezőtlen esetek a mintában), és ennek az oszlopnak az átlagára vonatkozó hipotézivizsgálatot végzünk (mivel $n=100 \geq 100$ ez simán lehet z-próba).

Ezzel a fenti elvvel viszont van egy kis gond! Ugyanis **arányra vonatkozó hipotézivizsgálat esetén a próbafüggvényünk az alábbi módon néz ki**:  $$\frac{p-P_0}{\sqrt{\frac{P_0(1-P_0)}{n}}} \sim N(0,1)$$

A **"kis gond"** a képlet nevezőjével, azaz a **standard hibával van**. A képlet madártávlatból nézve azt mondja, hogy vegyük minta és hipotetikus arány különbségét ($p-P_0$) osztva az arány standard hibájával. Ami tényleg az átlagra vonatkozó hipotézisvizsgálat próbafüggvényének működési elve, amit láttunk is a 2. fejezetben. DE! A **standard hibában a képlet az elvi arányt ($P_0$)** használja a mintából számolt arány ($p$) helyett. Viszont, ha egy $0-1$ értékekből álló oszlop átlagára vonatkozó hipotézisvizsgálatként számolnánk végig ezt a próbafüggvényt, akkor bizony a nevezőben $\sqrt{\frac{p(1-p)}{n}}$-gyel számolnánk $\sqrt{\frac{P_0(1-P_0)}{n}}$ helyett. Szóval mindenképpen külön, saját magunknak kell kiszámolni a próbafüggvényt manuálisan. A p-érték számolása standard normális ($N(0,1)$) eloszlásból történik már úgy, mint az átlag esetében láttuk a 2. és 3. fejezetekben. Ezért is *z-próba*ként emlegetjük ezt a hipotézisvizsgálatot is.

A próba elvégzéséhez először ki kell számolni a minta teljes elemszámát ($n$) és az arány szempontjából kedvező esetek számát ($k$), ami most esetünkben a $180$ percnél tovább úszók száma. Ezekből már akár a mintabeli arányt ($p$) is kiszámíthatjuk.

```{r}
# sample size
n <- nrow(swimming_sample)

# favourable cases for the proportion
fav <- sum(swimming_sample$TIME > 180)

# sample proportion
p <- fav/n
p
```

Ezzel látjuk, hogy a mintában a $180$ percnél tovább úszók aránya kereken $27\%$, ami nem egyenlő az $0.3 = 30\%$-al, így **a $H_1$ néz ki igaz állításnak**. Viszont, **ez simán lehet a mintavételi hiba műve is**, hiszen csak egy $n=100$ elemű mintából dolgozom, **nem látom az összes átúszó sokaságát**. Épp **ezért kell a p-érték**, ami megadja, hogy mennyire valószínű, hogy az a tény, hogy a megfigyelt mintában $0.27 \neq 0.30$ szignifikáns eltérés-e mintaarány és elvi arány között.

Jöhet akkor megadott képlet szerinti próbafüggvény számítás, majd a bal oldali próba szabályai szerint a p-érték számítás standard normális eloszlásból.

```{r}
# hypothetical proportion
P_0 <- 0.3

test_stat_p <- (p-P_0)/(sqrt(P_0*(1-P_0)/n))

p_val_for_prop <- 2*pnorm(test_stat_p) # two-tailed test -> 2*
p_val_for_prop
```

A p-értékünk magas, $51.2\%$, szóval ennyi esélyünk nagyobb eltérést kapni $H_0$-hoz képest, mint amit megfigyeltünk. Ez jó magas valsózínűség, magasabb, mint a legmagasabb szokásos szignifikancia-szint ($10\%$), így **azt mondjuk, hogy a $H_0$-t nem tudjuk elutasítani**. **Valós, sokasági aránya a $180$ percnél lassabban úszóknak simán vehető $30\%$-nak; a mintaarány és a $0.3$ közötti eltérés NEM szignifikáns**.

A hipotézisvizsgálatnak, mivel z-próba és standard normális eloszlásból számol p-értéket, előfeltétele, hogy nagy mintánk van. Ez most azt jelenti, hogy a $n \times P_0$ és $n \times (1-P_0)$ szorzat is legyen nagyobb mint $10$. Tehát, **az arány szempontjából kedvező és kedvezőtlen esetek száma is legyen legalább $10$ igaz nullhipotézis esetén**.

Lássuk, hogy teljesülnek-e akkor a feltételek:

```{r}
n*P_0
n*(1-P_0)
```

A $30$ és a $70$ is $10$-nél nagyobb szám, szóval rendben vagyunk! :)

## 5. A hipotézisvizsgálat menete madártávlatból

Az eddigiek alapján akkor azt mondhatjuk el, hogy igazából **bármilyen statisztikai mutatóra/paraméterre** (átlag, arány, stb.) **vonatkozik a hipotézisvizsgálatunk, annak mindig $4$ fő lépése van**.

1. Az alapállításból **null- és alternatív hipotézisek** ($H_0$ és $H_1$) felírása
2. Megfigyelt $n$ elemű mintaadatokból **próbafüggvény** számítása
3. A próbafüggvény és egy nevezetes eloszlás alapján **p-érték** számítása
4. A p-érték alapján annak el**döntés**e, hogy $H_0$ vagy $H_1$ vehető-e igaz állításnak a teljes sokaságban

Ez a $4$ lépés tényleg **minden hipotézisvizsgálat során ugyan ez lesz**, és **az $1.$ és $4.$ pontoknak is mindig ugyan az az elve, amiket eddig láttunk**, ezek nem változnak. Bármi is történik, a $H_0$ és $H_1$ felírás és közöttük a döntés *p-érték* alapján fix szabályok szerint működik. Ami az **egyes esetekben eltérő lehet, az a $2.$ és $3.$ pont**, ahol a próbafüggvényeket és a p-értékeket számoljuk. De **ezekre a pontokra szinte mindig lesz beépített Python függvény, csak azoknak a paraméterezését és a használatok előfeltételét kell** igazából **jól tudni**.