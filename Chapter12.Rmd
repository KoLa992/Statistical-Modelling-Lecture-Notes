---
title: "Non-Parametric Tests"
author: "László Kovács"
date: "06/04/2025"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. The General Concept of Non-Parametric Tests

We continue performing hypothesis tests.

UP UNTIL NOW, we examined the case of so-called **parametric tests**. In those, we made statments — hypotheses — about possible population values of statistical indicators, i.e. statistical parameters (e.g., mean, standard deviation, proportion, etc.).

NOW, we begin exploring the case of so-called **non-parametric tests**. In this case, we **make statements — hypotheses about the population distribution of variables**. A variable’s distribution basically means specifying what proportion each possible value of the variable occurs with. So really, in these hypotheses, we are making statements about **many proportion values at once**.

However, the **four fundamental steps remain unchanged** compared to before!

1. Writing $H_0$ and $H_1$
2. Computing the test statistic from the observed sample
3. Calculating the p-value based on the test statistic and a probability distribution
4. Decision based on the p-value $\rightarrow$ Can $H_0$ or $H_1$ be accepted as true for the population?

We will explore the topic of non-parametric tests using the <a href="https://github.com/KoLa992/Statistical-Modelling-Lecture-Notes/blob/main/StackOverflowHungary2020.xlsx" target="\_blank">StackOverflowHungary2020.xlsx</a> dataset, which comes from Stack Overflow's 2020 global survey of amateur and professional programmers across *60* variables. The full dataset (as well as past and future surveys) is available at [this link]((https://insights.stackoverflow.com/survey)).<br>
Our Excel file available on Moodle contains responses from only the *210 Hungarian respondents* of the 2020 survey, with data for the following *9* variables:

- **Age**: Respondent’s age (in years)
- **Age1stCode**: Age when the respondent wrote their first line of code (in years)
- **YearsCodePro**: Years of programming experience (excluding time spent studying)
- **MonthlyHuf**: Gross monthly salary in Hungarian Forints
- **Gender**: Respondent’s gender
- **EdLevel**: Highest level of completed education
- **Employment**: Employment status (full-time; part-time; self-employed)
- **JobSat**: Satisfaction with current job
- **OpSys**: Operating system preferred (Windows; Linux; MacOS)

Let’s load the dataset from Excel into a data frame and check with the `str` function whether all the variables listed above are present!

```{r}
library(readxl)

# Read the StackOverflow 2020 Survey Data for Hungarian Respondents
sfH <- read_excel("StackOverflowHungary2020.xlsx")
str(sfH)
```

It seems that all $210$ observations and the $9$ variables we are analyzing are there. Yeah! :))

## 2. Goodness-of-Fit Tests

One major subtype of non-parametric tests is the case of goodness-of-fit tests. In these, we always examine whether the **distribution of the observed sample elements fits a theoretical distribution specified by us** (e.g., uniform distribution or normal distribution, things like that).

### 2.1. Test of Representativity

**Representativeness according to a single variable**: the sample’s distribution with respect to a specific variable is approximately the same as the distribution of that variable in the entire (unobserved) population.

According to data from the Hungarian Central Statistical Office (HCSO) from 2020, in the Hungarian information and communication technology sector:

- $85\%$ are employed full-time,
- $4\%$ are part-time,
- $11\%$ are self-employed.

Given these proportions of employment types (i.e., the distribution of job types), **is the Hungarian sample from the StackOverflow questionnaire representative in terms of employment types?**

In this case:

- $H_0:$ The sample is **representative**
- $H_1:$ The sample is **NOT representative**

Our test statistic and the distribution used to compute the p-value under the assumption that $H_0$ is true is the following: $$\sum_{j=1}^{k}{\frac{(f_j-f^*_j)^2}{f^*_j}} \sim \chi^2(k-1)$$

Meaning of the symbols in the formula:

- $k$: the number of possible values (categories) of the variable under examination
- $f_j$: observed frequencies of each variable value
- $f^*_j$: theoretical frequencies of the examined variable values in the sample if it were representative

The **p-value** is **always** calculated from the $\chi^2(k - 1)$ distribution in a **right-tailed** manner. For more details on calculating right-tailed p-values, see <a href="Chapter10.html" target="_blank">Section 2 of Chapter 10</a>.

Let’s compute the necessary $f_j$ frequencies.

```{r}
observed_freq <- table(sfH$Employment)
observed_freq
```

Now, let’s move on to the theoretical $P_j$ probabilities! What would be the probability of each job type if the $n = 210$ sample were completely representative? Be sure to provide them in the same order as the job types appear in the `observed_freq` vector.

```{r}
theor_probs <- c(0.85, 0.04, 0.11)
theor_probs
```

Could the difference between the theoretical and actual frequencies, calculated from $P_j$, be attributed to sampling error? $\rightarrow$ Hypothesis test :)

We can calculate the test statistic and p-value using a built-in R function called `chisq.test`. Here, the degrees of freedom are $df = k - 1 = 3 - 1 = 2$. This interpretation of degrees of freedom (i.e., $df = k - 1$) is the function’s default, so we don’t need to set it separately.

```{r}
chisq.test(observed_freq, p = theor_probs)
```

Our p-value is $7.1\%$. This falls within the typical significance level range (1%–10%). We would **need a larger sample to make a definitive decision**. But since we're closer to $10\%$ than to $1\%$ $\rightarrow$ the **sample seems more representative than not**. :)

Our assumption is that each expected frequency is at least $5$, i.e., $\forall f^*_j \geq 5$. Let’s check that quickly!

```{r}
nrow(sfH)*theor_probs >= 5
```

In all three cases, we have at least $5$ expected observations, so we’re good! Woohoo! :)

By the way, we can also retrieve the $f^_j$ values if we save the result of the `chisq.test` function into an R memory object. This will be a `list`-type object, and the expected frequencies used for the test statistic calculation (i.e., the $f^*_j$ frequencies under $H_0$) are stored in the `expected` element of the list.

```{r}
representativity_result <- chisq.test(observed_freq, p = theor_probs)
representativity_result$expected
```

Again, we can see that in all three cases there are at least $5$ expected observations — we’re good! Don’t be scared by the fractional numbers — we see those because these are **theoretical frequencies measured in an imagined state of the world**, where $H_0$ (representativeness) is entirely true. In such imaginary worlds, fractional frequencies are totally allowed. :)

### 2.2. Test of Normality

Our statement is that the **age distribution of Hungarian programmers at the time they wrote their first code follows a normal distribution**

The first way to test this claim is the "*eyeball test*" = histogram.

```{r}
hist(sfH$Age1stCode)
```

The histogram is roughly normally distributed, but it has a slight right tail.

Question: Is this slight right-skew due to sampling error? $\rightarrow$ Hypothesis test! :)

- $H_0:$ The distribution is **normal**
- $H_1:$ The distribution is **NOT normal**

To **compute the test statistic and p-value, we'll use a trick**! We calculate the quintiles (i.e., 5-part dividing points) of the normal distribution that best fits the `Age1stCode` variable. For example, $K_2$ is the value below which 40% (i.e., $2/5$) of the data fall, and above which 60% ($3/5$) lie.<br>
The best-fitting normal distribution for the `Age1stCode` variable is the one that has the same mean and standard deviation as the observed `Age1stCode` values.

Let’s compute the appropriate mean and standard deviation. The standard deviation should be corrected (sample-based) so that we avoid bias! This is essentially *method-of-moments* based fitting. :)

```{r}
sample_mean = mean(sfH$Age1stCode)
s = sd(sfH$Age1stCode)
```

The quintiles of the normal distribution can be calculated using the `qnorm` function. The quintile values must be passed as a vector to the function. For technical reasons, we also need the $0$ and $1 = 100\%$ cut points in addition to the $0.2$ increments = quintiles = five-part points.

```{r}
norm_quintiles <- qnorm(c(0,0.2, 0.4, 0.6, 0.8,1), mean = sample_mean, sd = s)
norm_quintiles
```

Next, we create a frequency table of the $f_j$ values corresponding to the normal distribution quintiles. First, we use the `cut` function to split the variable according to the quintile values given in the `breaks` parameter. Then we use the `table` function to count the frequencies within these intervals.

```{r}
observed_freq <- table(cut(sfH$Age1stCode, breaks = norm_quintiles))
observed_freq
```

If $H_0$ (i.e., normal distribution) were true, then these quintiles would split the sample perfectly into five equal parts. So, the expected frequencies would be: $f^*_j = \frac{n}{5} = \frac{210}{5} = 42$. This is the default setting for $f^*_j$ in `chisq.test`. That is, unless we specify otherwise, the function assumes $1/5 = 0.2$ for each category in the `p` parameter.

Let’s compute the test statistic and the p-value with this default assumption for $f^*_j$. We have everything: we know the $f_j$ and the $f^*_j$ values. However, for the p-value, the appropriate distribution is $\chi^2(k - 1 - b)$, where $b$ is the number of estimated parameters. In our case, these are the mean and standard deviation of the best-fitting normal distribution, so $b = 2$. We must override the default degrees of freedom (`df`) in `chisq.test` using this $b = 2$ value. We do this by manually computing the p-value based on the test statistic returned from `chisq.test`, using the $\chi^2(k - b - 1)$ distribution. So, Degrees of freedom = $k - 1 - b$. Here, $k = 5$ (due to quintiles) and $b = 2$ (mean + standard deviation estimated from sample).

```{r}
chi2_result <- chisq.test(observed_freq)
p_value_chi2 <- 1-pchisq(chi2_result$statistic, df = 5-2-1)
p_value_chi2*100 # in percentage format
```

Our p-value is $0.0075\%$, which is smaller than even the most conservative standard significance level of $1\%$. Thus, $H_0$ can be confidently rejected — the **distribution cannot be considered normal**.

```{r}
chi2_result$expected
```

So, the slight right-tail observed in the histogram compared to the normal distribution is NOT due to sampling error — it’s a significant deviation that would persist even outside the observed sample!

Naturally, this method works with other quantiles too — e.g., deciles! Just make sure your chosen quantiles satisfy the condition $\forall f^*_j \geq 5$. In our case, deciles (10-part division points) would work too, because $210 / 10 = 21 > 5$. It may even be beneficial to use more cut points, as this lets us more accurately assess the distribution in the test statistic. After all, a decision based on 10 frequency counts is better than one based on 5.

Furthermore, this quantile-based trick is not only usable for checking normality — it works for fitting any probability distribution (exponential, Poisson, log-normal, etc.)!

## 3. Test of Homogenity

Let’s examine the statement that, in the entire Hungarian programming population, **developers using Windows and those using other operating systems have the same level of job satisfaction**. In other words, the distribution of job satisfaction between Windows and non-Windows users is **homogeneous**.

We describe this base assumption using the following null and alternative hypothesis pair:

- $H_0:$ The two groups (Windows and non-Windows) have **identical distributions** in the population
- $H_1:$ The two groups (Windows and non-Windows) have **different distributions** in the population

To compute this, we first need to group the values of the `OpSys` variable into two categories — Windows and non-Windows — in a new variable, since it contains more than just "Windows" or "not Windows" values.

```{r}
unique(sfH$OpSys)
```

The `ifelse` function is excellent for this kind of grouping.

```{r}
sfH$OpSys_Groupped <- ifelse(sfH$OpSys=="Windows","Windows","NotWindows")
table(sfH$OpSys_Groupped)
```

To compute the test statistic, we need a contingency frequency table (crosstab) — just like the one we created for stacked bar plots in <a href="Chapter02.html" target="_blank">Section 4.4 of Chapter 2</a>.

This table shows the frequencies of each job satisfaction level (`JobSat`) for both the Windows and non-Windows groups.

```{r}
crosstab <- table(sfH[, c("JobSat", "OpSys_Groupped")])
crosstab
```

So for example, we observe that $31$ Windows users in our sample are very satisfied with their job.

Now let’s look at the proportions of job satisfaction within each operating system group!
We use the prop.table function with the second parameter set to 2, because we want to calculate proportions within the columns (2nd dimension) of the contingency table (i.e., percentage by column total).

```{r}
prop.table(crosstab,2)
```
So for instance, $38.8\%$ of non-Windows users are very satisfied with their job, while only $24.8\%$ of Windows users report the same level of satisfaction.

But are these **differences in satisfaction proportions between operating systems just due to sampling error**? $\rightarrow$ Hypothesis test! :)

Our test statistic is the following: $$\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{(f_{ij}-f^*_{ij})^2}{f^*_{ij}}\sim\chi^2((r-1)(c-1))$$

A fenti képlet alapján igaz $H_0$ esetén a próbafüggvény eloszlása sok-sok mintavételből $\chi^2((r-1)(c-1))$, ahol $r$ a kereszttábla sorainak (*rows*), míg $c$ a kereszttábla oszlopainak (*columns*) a darabszáma.<br>
Az $f^*_{ij}$ elvi gyakoriság ebben az esetben azt mutatja meg, hogy mennyi olyan $i$ elégedettségi értékű megfigyelés lenne a $j$ operációsrendszer csoportban, ha az $i$ értékek eloszlása a $j$ csoportokban azonos lenne. Ez más szóval azt jelenti, hogy a **homogenitás $H_0$-ja azt jelenti, hogy az $i$ és $j$ értékek egymástól FÜGGETLENEK** --> A $j$ csoportosítás nem befolyásolja az $i$ értékek eloszlását, emiatt minden $j$ csoportban azonos. Emiatt az $f^*_{ij}$ elvi gyakoriságok a független valószínűségekre vonatkozó szorzési szabály (független $i$ és $j$ esetén egy adott $ij$ páros bekövetkezési valószínűsége az $i$ és $j$ külön-külön vett valószínűségeinek szorzata) alapján számítható: $$f^*_{ij}=\frac{f_{i.}f_{.j}}{n}$$

Ahol $f_{i.}$ és $f_{.j}$ értékek rendre az összes $i$ és összes $j$ értékek előfordulási gyakoriságai a mintában. Más néven az úgynevezett **peremgyakoriságok**.

A próbafüggvény megadása után a **p-érték** itt is **jobboldali módon** számolható, mint az illeszkedésvizsgáaltok esetében.

Próbafüggvény és p-érték számolás a `chisq.test` beépített függvénnyel most is megoldható. Bemenet csak a kereszttábla, ebben az esetben a szabadságfokot is ebből ki tudja számoln a függvény.

```{r}
chisq.test(crosstab)
```

A p-értékünk itt $20.4\%$, ami nagyobb még a legnagyobbszokásos szignifikancia-szintnél a $10\%$-nál is. A mintán kívüli világban, azaz a **sokaságban a munkával vett elégedttségek eloszlása AZONOSNAK tekinthető Windows és nem Windows felhasználók esetén**.<br>
Az a tény, hogy a megfigyelt mintában az elégedettségi arányok eltérnek operációs rendszerek között csak a mintavételi hiba műve, nem szignifikáns!

A `chisq.test` függvény eredményéül kapott listában az `expected` elem az a kereszttábla, ami igaz $H_0$, azaz a két ismérv függetlensége esetén lenne. A `prop.table` függvénnyel ellenőrizhető is, hogy ebben a kereszttáblában az oszlopösszeg (azaz a két operációs rendszer csoport) százalékában kifejezett arányok azonosak itt, ahogy a $H_0$ állítja.

```{r}
homogenity_result <- chisq.test(crosstab)
prop.table(homogenity_result$expected,2)
```


Ha $H_0$ elutasítható lenne, akkor érdekes lenne, hogy a megfiyelt mintában a kereszttábla (az $f_{ij}$-k) hol tér el a legjobban a függetlenség esetén várt gyakoriságoktól, az $f^*_{ij}$-ktől.

Ezeket az $f_{ij}-f^*_{ij}$ eltéréseket ekemezve szépen látható, hogy hogy kb. $7$-tel kevesebb nagyon elégedett Windowsos van a mintában, mint függetlenség ($H_0$) esetén lennie kéne, és kb. $3$-al több enyhén elégedetlen Windowsos van a mintában, mint függetlenség esetén kéne.

```{r}
homogenity_result$observed - homogenity_result$expected
```

A **próba elvégzésének előfeltétele**, hogy a $H_0$ szerinti elvi kereszttáblában minden $f^*_{ij}\geq5$. Szerenére ez teljesül is.

```{r}
homogenity_result$expected>=5
```

Ha esetleg ez a feltétel mégsem teljesülne a mintánkon, akkor itt pl. úgy lehetne áthidalni a problémát, hogy a **logikusan összevonható kategóriákat összevonjuk**. Pl. a *Very satisfied* és *Slightly satisfied* kategóriákból készítünk egy *Satisfied* kategóriát, a többiekből pedig egy *Not satisdfied kategóriát*. Ezt az `ifelse` függvénnyel tudjuk itt is simán intézni.

```{r}
sfH$JobSat_v2 <- ifelse(sfH$JobSat %in% c("Very dissatisfied", "Slightly dissatisfied"), "Dissatisfied", sfH$JobSat)

crosstab_v2 <- table(sfH[, c("JobSat_v2", "OpSys_Groupped")])
crosstab_v2
```

És erre az új kereszttáblára is el tudjuk végezni a homogenitásvizsgálatot.

```{r}
chisq.test(crosstab_v2)
```

Látjuk, hogy érdemben nem kapunk más eredményt. A p-értékünk itt $17.1\%$, ami továbbra is magasabb a legnagyobb szokásos szignifikancia-szintnél (10%) is, így a $H_0$ most sem utasítható el.