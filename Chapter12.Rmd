---
title: "Non-Parametric Tests"
author: "László Kovács"
date: "06/04/2025"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. The General Concept of Non-Parametric Tests

We continue performing hypothesis tests.

UP UNTIL NOW, we examined the case of so-called **parametric tests**. In those, we made statments — hypotheses — about possible population values of statistical indicators, i.e. statistical parameters (e.g., mean, standard deviation, proportion, etc.).

NOW, we begin exploring the case of so-called **non-parametric tests**. In this case, we **make statements — hypotheses about the population distribution of variables**. A variable’s distribution basically means specifying what proportion each possible value of the variable occurs with. So really, in these hypotheses, we are making statements about **many proportion values at once**.

However, the **four fundamental steps remain unchanged** compared to before!

1. Writing $H_0$ and $H_1$
2. Computing the test statistic from the observed sample
3. Calculating the p-value based on the test statistic and a probability distribution
4. Decision based on the p-value $\rightarrow$ Can $H_0$ or $H_1$ be accepted as true for the population?

We will explore the topic of non-parametric tests using the <a href="https://github.com/KoLa992/Statistical-Modelling-Lecture-Notes/blob/main/StackOverflowHungary2020.xlsx" target="\_blank">StackOverflowHungary2020.xlsx</a> dataset, which comes from Stack Overflow's 2020 global survey of amateur and professional programmers across *60* variables. The full dataset (as well as past and future surveys) is available at [this link]((https://insights.stackoverflow.com/survey)).<br>
Our Excel file available on Moodle contains responses from only the *210 Hungarian respondents* of the 2020 survey, with data for the following *9* variables:

- **Age**: Respondent’s age (in years)
- **Age1stCode**: Age when the respondent wrote their first line of code (in years)
- **YearsCodePro**: Years of programming experience (excluding time spent studying)
- **MonthlyHuf**: Gross monthly salary in Hungarian Forints
- **Gender**: Respondent’s gender
- **EdLevel**: Highest level of completed education
- **Employment**: Employment status (full-time; part-time; self-employed)
- **JobSat**: Satisfaction with current job
- **OpSys**: Operating system preferred (Windows; Linux; MacOS)

Let’s load the dataset from Excel into a data frame and check with the `str` function whether all the variables listed above are present!

```{r}
library(readxl)

# Read the StackOverflow 2020 Survey Data for Hungarian Respondents
sfH <- read_excel("StackOverflowHungary2020.xlsx")
str(sfH)
```

It seems that all $210$ observations and the $9$ variables we are analyzing are there. Yeah! :))

## 2. Goodness-of-Fit Tests

One major subtype of non-parametric tests is the case of goodness-of-fit tests. In these, we always examine whether the **distribution of the observed sample elements fits a theoretical distribution specified by us** (e.g., uniform distribution or normal distribution, things like that).

### 2.1. Test of Representativity

**Representativeness according to a single variable**: the sample’s distribution with respect to a specific variable is approximately the same as the distribution of that variable in the entire (unobserved) population.

According to data from the Hungarian Central Statistical Office (HCSO) from 2020, in the Hungarian information and communication technology sector:

- $85\%$ are employed full-time,
- $4\%$ are part-time,
- $11\%$ are self-employed.

Given these proportions of employment types (i.e., the distribution of job types), **is the Hungarian sample from the StackOverflow questionnaire representative in terms of employment types?**

In this case:

- $H_0:$ The sample is **representative**
- $H_1:$ The sample is **NOT representative**

Our test statistic and the distribution used to compute the p-value under the assumption that $H_0$ is true is the following: $$\sum_{j=1}^{k}{\frac{(f_j-f^*_j)^2}{f^*_j}} \sim \chi^2(k-1)$$

Meaning of the symbols in the formula:

- $k$: the number of possible values (categories) of the variable under examination
- $f_j$: observed frequencies of each variable value
- $f^*_j$: theoretical frequencies of the examined variable values in the sample if it were representative

We need to note here that technically the $H_0$ and $H_1$ pairs of these non-parametric tests state the following:

- $H_0: f_j=f^*_j ,\forall j$
- $H_1: \exists j: f_j \neq f^*_j$

So, even if in one category $j$ we have a significant difference in the observed frequency $f_j$ and the theoretical frequency $f^*_j$ under $H_0$, then $H_0$ is rejected, no matter that in the rest of the categories the observed frequencies fit to the theoretical distribution assumed in $H_0$.<br>
That is why **these $\chi^2$ non-parametric tests very much favor $H_1$, as it is a very strong statement**. This technical $H_0$ and $H_1$ pair remains in all subsequent non-parametric test of this chapter, so **this behavior of $H_1$ being a strong statement remains in all further $\chi^2$ non-parametric tests that we are covering in this chapter**.

The **p-value** is **always** calculated from the $\chi^2(k - 1)$ distribution in a **right-tailed** manner. For more details on calculating right-tailed p-values, see <a href="Chapter10.html" target="_blank">Section 2 of Chapter 10</a>.

Let’s compute the necessary $f_j$ frequencies.

```{r}
observed_freq <- table(sfH$Employment)
observed_freq
```

Now, let’s move on to the theoretical $P_j$ probabilities! What would be the probability of each job type if the $n = 210$ sample were completely representative? Be sure to provide them in the same order as the job types appear in the `observed_freq` vector.

```{r}
theor_probs <- c(0.85, 0.04, 0.11)
theor_probs
```

Could the difference between the theoretical and actual frequencies, calculated from $P_j$, be attributed to sampling error? $\rightarrow$ Hypothesis test :)

We can calculate the test statistic and p-value using a built-in R function called `chisq.test`. Here, the degrees of freedom are $df = k - 1 = 3 - 1 = 2$. This interpretation of degrees of freedom (i.e., $df = k - 1$) is the function’s default, so we don’t need to set it separately.

```{r}
chisq.test(observed_freq, p = theor_probs)
```

Our p-value is $7.1\%$. This falls within the typical significance level range (1%–10%). We would **need a larger sample to make a definitive decision**. But since we're closer to $10\%$ than to $1\%$ $\rightarrow$ the **sample seems more representative than not**. :)

Our assumption is that each expected frequency is at least $5$, i.e., $\forall f^*_j \geq 5$. Let’s check that quickly!

```{r}
nrow(sfH)*theor_probs >= 5
```

In all three cases, we have at least $5$ expected observations, so we’re good! Woohoo! :)

By the way, we can also retrieve the $f^*_j$ values if we save the result of the `chisq.test` function into an R memory object. This will be a `list`-type object, and the expected frequencies used for the test statistic calculation (i.e., the $f^*_j$ frequencies under $H_0$) are stored in the `expected` element of the list.

```{r}
representativity_result <- chisq.test(observed_freq, p = theor_probs)
representativity_result$expected
```

Again, we can see that in all three cases there are at least $5$ expected observations — we’re good! Don’t be scared by the fractional numbers — we see those because these are **theoretical frequencies measured in an imagined state of the world**, where $H_0$ (representativeness) is entirely true. In such imaginary worlds, fractional frequencies are totally allowed. :)

### 2.2. Test of Normality

Our statement is that the **age distribution of Hungarian programmers at the time they wrote their first code follows a normal distribution**

The first way to test this claim is the "*eyeball test*" = histogram.

```{r}
hist(sfH$Age1stCode)
```

The histogram is roughly normally distributed, but it has a slight right tail.

Question: Is this slight right-skew due to sampling error? $\rightarrow$ Hypothesis test! :)

- $H_0:$ The distribution is **normal**
- $H_1:$ The distribution is **NOT normal**

To **compute the test statistic and p-value, we'll use a trick**! We calculate the quintiles (i.e., 5-part dividing points) of the normal distribution that best fits the `Age1stCode` variable. For example, $K_2$ is the value below which 40% (i.e., $2/5$) of the data fall, and above which 60% ($3/5$) lie.<br>
The best-fitting normal distribution for the `Age1stCode` variable is the one that has the same mean and standard deviation as the observed `Age1stCode` values.

Let’s compute the appropriate mean and standard deviation. The standard deviation should be corrected (sample-based) so that we avoid bias! This is essentially *method-of-moments* based fitting. :)

```{r}
sample_mean = mean(sfH$Age1stCode)
s = sd(sfH$Age1stCode)
```

The quintiles of the normal distribution can be calculated using the `qnorm` function. The quintile values must be passed as a vector to the function. For technical reasons, we also need the $0$ and $1 = 100\%$ cut points in addition to the $0.2$ increments = quintiles = five-part points.

```{r}
norm_quintiles <- qnorm(c(0,0.2, 0.4, 0.6, 0.8,1), mean = sample_mean, sd = s)
norm_quintiles
```

Next, we create a frequency table of the $f_j$ values corresponding to the normal distribution quintiles. First, we use the `cut` function to split the variable according to the quintile values given in the `breaks` parameter. Then we use the `table` function to count the frequencies within these intervals.

```{r}
observed_freq <- table(cut(sfH$Age1stCode, breaks = norm_quintiles))
observed_freq
```

If $H_0$ (i.e., normal distribution) were true, then these quintiles would split the sample perfectly into five equal parts. So, the expected frequencies would be: $f^*_j = \frac{n}{5} = \frac{210}{5} = 42$. This is the default setting for $f^*_j$ in `chisq.test`. That is, unless we specify otherwise, the function assumes $1/5 = 0.2$ for each category in the `p` parameter.

Let’s compute the test statistic and the p-value with this default assumption for $f^*_j$. We have everything: we know the $f_j$ and the $f^*_j$ values. However, for the p-value, the appropriate distribution is $\chi^2(k - 1 - b)$, where $b$ is the number of estimated parameters. In our case, these are the mean and standard deviation of the best-fitting normal distribution, so $b = 2$. We must override the default degrees of freedom (`df`) in `chisq.test` using this $b = 2$ value. We do this by manually computing the p-value based on the test statistic returned from `chisq.test`, using the $\chi^2(k - b - 1)$ distribution. So, Degrees of freedom = $k - 1 - b$. Here, $k = 5$ (due to quintiles) and $b = 2$ (mean + standard deviation estimated from sample).

```{r}
chi2_result <- chisq.test(observed_freq)
p_value_chi2 <- 1-pchisq(chi2_result$statistic, df = 5-2-1)
p_value_chi2*100 # in percentage format
```

Our p-value is $0.0075\%$, which is smaller than even the most conservative standard significance level of $1\%$. Thus, $H_0$ can be confidently rejected — the **distribution cannot be considered normal**.

```{r}
chi2_result$expected
```

So, the slight right-tail observed in the histogram compared to the normal distribution is NOT due to sampling error — it’s a significant deviation that would persist even outside the observed sample!

Naturally, this method works with other quantiles too — e.g., deciles! Just make sure your chosen quantiles satisfy the condition $\forall f^*_j \geq 5$. In our case, deciles (10-part division points) would work too, because $210 / 10 = 21 > 5$. It may even be beneficial to use more cut points, as this lets us more accurately assess the distribution in the test statistic. After all, a decision based on 10 frequency counts is better than one based on 5.

Furthermore, this quantile-based trick is not only usable for checking normality — it works for fitting any probability distribution (exponential, Poisson, log-normal, etc.)!

## 3. Test of Homogenity

Let’s examine the statement that, in the entire Hungarian programming population, **developers using Windows and those using other operating systems have the same level of job satisfaction**. In other words, the distribution of job satisfaction between Windows and non-Windows users is **homogeneous**.

We describe this base assumption using the following null and alternative hypothesis pair:

- $H_0:$ The two groups (Windows and non-Windows) have **identical distributions** in the population
- $H_1:$ The two groups (Windows and non-Windows) have **different distributions** in the population

To compute this, we first need to group the values of the `OpSys` variable into two categories — Windows and non-Windows — in a new variable, since it contains more than just "Windows" or "not Windows" values.

```{r}
unique(sfH$OpSys)
```

The `ifelse` function is excellent for this kind of grouping.

```{r}
sfH$OpSys_Groupped <- ifelse(sfH$OpSys=="Windows","Windows","NotWindows")
table(sfH$OpSys_Groupped)
```

To compute the test statistic, we need a contingency frequency table (crosstab) — just like the one we created for stacked bar plots in <a href="Chapter02.html" target="_blank">Section 4.4 of Chapter 2</a>.

This table shows the frequencies of each job satisfaction level (`JobSat`) for both the Windows and non-Windows groups.

```{r}
crosstab <- table(sfH[, c("JobSat", "OpSys_Groupped")])
crosstab
```

So for example, we observe that $31$ Windows users in our sample are very satisfied with their job.

Now let’s look at the proportions of job satisfaction within each operating system group!
We use the prop.table function with the second parameter set to 2, because we want to calculate proportions within the columns (2nd dimension) of the contingency table (i.e., percentage by column total).

```{r}
prop.table(crosstab,2)
```
So for instance, $38.8\%$ of non-Windows users are very satisfied with their job, while only $24.8\%$ of Windows users report the same level of satisfaction.

But are these **differences in satisfaction proportions between operating systems just due to sampling error**? $\rightarrow$ Hypothesis test! :)

Our test statistic is the following: $$\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{(f_{ij}-f^*_{ij})^2}{f^*_{ij}}\sim\chi^2((r-1)(c-1))$$

Under $H_0$, the distribution of this test statistic — based on many samples — follows the $\chi^2((r-1)(c-1))$ distribution, where $r$ is the number of rows (job satisfaction levels), and $c$ is the number of columns (OS groups) in the contingency table.<br>
Here, $f^*_{ij}$ is the expected frequency — it tells us how many observations of satisfaction level $i$ we’d expect in OS group $j$ if the distribution of $i$ were identical across all $j$ groups. In other words, **the homogeneity $H_0$ states also means that job satisfaction and operating system are INDEPENDENT as random variables** $\rightarrow$ the grouping variable $j$ does not influence the distribution of $i$, and hence it is the same (homogeneous) in all groups.

Thus, the expected frequencies can be computed using the multiplication rule for independent probabilities, which states in case of independent $i$ and $j$ the probabaility of the $ij$ pair occurring together is the multiplication of the probabilities that $i$ and $j$ occurs separately: $$f^*_{ij}=\frac{f_{i.}f_{.j}}{n}$$

Where $f_{i.}$ and $f_{.j}$ are the total counts of the values $i$ and $j$ in the sample respectively — also known as the **marginal frequencies**.

We need to note here too that technically the $H_0$ and $H_1$ pairs of this test of homogeneity state the following:

- $H_0: f_{ij}=f^*_{ij} ,\forall i,j$
- $H_1: \exists i,j: f_{ij} \neq f^*_{ij}$

So, even if in one $i$ and $j$ pairing, we have a significant difference in the observed frequency $f_{ij}$ and the theoretical frequency $f^*_{ij}$ under $H_0$, then $H_0$ is rejected, no matter that in the rest of the pairs, the observed frequencies fit to the homogeneous distribution assumed in $H_0$.<br>
That is why **this $\chi^2$ test of homogeneity also very much favors $H_1$, as it is a very strong statement here as well**.

After calculating the test statistic, the **p-value** is computed in a **right-tailed** manner — just like in goodness-of-fit tests.

We can calculate the test statistic and p-value using the built-in `chisq.test` function. We only need the contingency table (frequency crosstab) as input — the function can calculate the degrees of freedom automatically.

```{r}
chisq.test(crosstab)
```

In our case, the p-value is $20.4\%$, which is higher than even the highest typical significance level of $10\%$.
So **in the population** (i.e., outside of our sample), **the distrobution of job satisfaction levels can be considered IDENTICAL between Windows and non-Windows users**.<br>
In other words, the observed difference in satisfaction rates between operating systems in our sample is likely due to sampling error alone — not statistically significant.

The `expected` element in the result list returned by `chisq.test` is the contingency table that would occur if $H_0$ were true (i.e., if the two groups were to have the same job satiosfaction distrobution). We can verify using `prop.table` that in this theoretical contingency table, the proportions within columns = OS groups are indeed equal — just as $H_0$ states.

```{r}
homogenity_result <- chisq.test(crosstab)
prop.table(homogenity_result$expected,2)
```

If $H_0$ could be rejected, it would be interesting to see where the observed values $f_{ij}$ differ most from the expected $f^*_{ij}$.

By examining the differences $f_{ij} - f^*_{ij}$, we can clearly see, for example, that there are about $7$ fewer very satisfied Windows users in the sample than we would expect under independence ($H_0$), and about $3$ more slightly dissatisfied Windows users than expected under $H_0$.

```{r}
homogenity_result$observed - homogenity_result$expected
```

The **assumption for performing this test of homogeneity** is that all expected frequencies $f^*_{ij} \geq 5$. Fortunately, this condition is met.

```{r}
homogenity_result$expected>=5
```

If this condition were not met in our sample, we could resolve it by **merging logically related categories**. For example, we could merge *Very satisfied* and *Slightly satisfied* into a new *Satisfied* category, and merge the others into a *Not satisfied* category. We can again use `ifelse` to perform this grouping.

```{r}
sfH$JobSat_v2 <- ifelse(sfH$JobSat %in% c("Very dissatisfied", "Slightly dissatisfied"), "Dissatisfied", sfH$JobSat)

crosstab_v2 <- table(sfH[, c("JobSat_v2", "OpSys_Groupped")])
crosstab_v2
```

We can then repeat the test of homogeneity on this new contingency table.

```{r}
chisq.test(crosstab_v2)
```

We see that the result does not change meaningfully: our p-value is $17.1\%$, still above the most common significance level of $10\%$, so we again fail to reject $H_0$.