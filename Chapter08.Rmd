---
title: "Confidence Interval for the Mean in IID Samples"
author: "László Kovács"
date: "07/03/2025"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. A Konfidencia-intervallumok két általános tulajdonsága

Az átlagra vonatkozó konfidencia-intervallumokkal kapcsolatos számolások során megállapítottunk **két olyan általános tulajdonságot a konfidencia-intervallumok hosszára, azaz a teljes becslési hibahatárra** $\triangle$-re vonatkozóvan, **amelyek igazak lesznek az összes többi** - a tárgyban vizsgált - **statisztikai mutató konfidencia-intervallumára** is:

1. A megbízhatóság növelésével a konfidencia-intervallum egyre csak tágul, azaz a becslési hibahatár folyamatosan nő. Tehát, **nagyobb megbízhatóságú becslés csak pontatlanabb konfidencia-intervallum árán érhető el**.
2. Mivel a továbbiakban is konzisztensen viselkedő becslőfüggvényekkel ($\hat{\theta}$-kal) fogunk dolgozni, így kijelenthető, hogy a **mintaelemszám ($n$) növelésével**, a $SH$ értéke csökken. A csökkenő $SE$ miatt pedig **az egész konfidencia-intervallum pontosabb lesz**. **Magyarul**  az elemszém növelésével a konfidencia-intervallum hossza, leánykori nevén **becslési hibahatár** ($\triangle$) **csökken**.

A következő két fejezetben figyeljük meg, hogy **minden újabb statisztikai mutató konfidencia-intervalluma a feni két tulajdonságot betartva fog viselkedni**!

## 2. Arányok konfidencia-intervalluma

Vegyük elő újra a <a href="https://github.com/KoLa992/Statistical-Modelling-Lecture-Notes/blob/main/ESS2020.xlsx" target="_blank">ESS2020.xlsx</a> fájlban található adatbázist! Emlékeztetőül álljon itt, hogy ez az adatbázis a 2020-ban végzett európai szociális felmérés (European Social Survey 2020 = ESS2020) 1849 magyar kitöltöjének válaszait tartalmazza 14 kérdésre (plusz van egy *id* oszlop).

Ugyebár az <a href="Chapter07.html" target="_blank">Section 4 of Chapter 7</a>-ben azt mondtuk, hogy ha az adatbázis valamelyik oszlopában üres értéket találunk, akkor az azt jelenti, hogy az adott sorban lévő kitöltő nem válaszolt a kérdésre. Az adatbázisban szereplő kitöltők a teljes 18 év feletti magyar népességből vett véletlen mintaként kezelhetők. Most feltesszük, hogy ez a véletlen minta visszatevéses, azaz $FAE$ is. A következő tananyagban látni fogjuk, hogy ez nem is valóságtól elrugaszkodott feltevés.

Először is töltsök be az adatbázist ismét az Excelből egy `pandas` data frame-be és nézzük meg az `str` függvénnyel milyen oszlopaink (azaz ismérveink) vannak!

```{r}
library(readxl)

ESS <- read_excel("ESS2020.xlsx")
str(ESS)
```

Láthatjuk, hogy megvan mind a 14+1 oszlopunk a megfelelő adattípusokkal. Hurrá! :)

**Feladatunk** ezúttal az lenne, hogy **99%-os megbízhatóságú konfidencia-intervallum**ot építsünk a **Fideszt támogatók arányára!**

Szerencsére ezt aránylag könnyű megtenni, hiszen **egy adott tulajdonsággal bíró egyedek aránya lényegében egy átlag**! Konkrétan **egy olyan változó átlaga, ahol a tulajdonsággal bíró egyedek $1$ értéket, míg a tulajdonsággal NEM rendelkező egyedek $0$ értéket kapnak**.

Ezt könnyű is szemléltetni Python-ban. Vegyük a feladat szempontjából releváns a `PoliticalPartyPref` ismérv **relatív gyakoriságait** a `table` és  `prop.table` függvények segítségével:

```{r}
prop.table(table(ESS$PoliticalPartyPref))
```

Ez alapján ugye a Fidesz kormánypárt támogatóinak aránya a megfigyelt 1849 elemű mintában $19.7\%$. Ezt az eredményt pedig úgy is megkaphatjuk, hogy csinálunk egy új `Fidesz` nevű oszlopot az `ESS` nevű data frame-be, amiben a Fidesz támogatók $1$ értéket kapnak, a többiek $0$-t, és vesszük az új oszlop átlagát.<br>
Az új oszlop létrehozásához az `ifelse` néven futó függvényét használjuk. Ez lényegében olyan, mint az Excel `HA` függvénye: egy logikai feltétel megadása után értéket adunk az új oszlopban a *feltétel igaz* ágon, majd utána a *feltétel hamis* ágon.

```{R}
# Create the new column called 'Fidesz'
ESS$Fidesz <- ifelse(ESS$PoliticalPartyPref=='Fidesz-KDNP', 1, 0)

# And take the mean of this new column
mean(ESS$Fidesz)
```

Ismét megkaptuk a $19.7\%$-os támogatottsági arányt. Ez alapján pedig könnyen elkészíthetjük rá a 99%-os megíbzhatóságú konfidencia-intervallumot az `rcompanion` csomag `groupwiseMean` függvényével. A nagy mintaelemszám miatt nincs lényegi különbség arra nézve, hogy a szükséges a $k$ szorzót t-eloszlásból vagy standard normális eloszlásból számítjuk, így tökéletes lesz a függvény által használt alapértelmezett t-eloszlás.

```{r}
library(rcompanion)

groupwiseMean(Fidesz~1, data = ESS, na.rm = TRUE, digits = 4, conf = 0.99)
```

Tehát, a mintánk alapján a **magyar népesség egészét tekintve az mondható el, hogy 99%-os valószínűséggel legalább $17.4\%$-uk támogatja a Fidesz-KDNP-t, viszont szintén 99%-os valószínűséggel kijelenthető, hogy a támogatottsági arányuk nem magasabb $22.1\%$-nál**.

Sőt, ha figyelembe vesszük, hogy a teljes magyar népesség 2020. január 1-jén 9 772 756 fő volt, akkor megkaphatjuk, hogy **konkrétan hány főnyi Fidesz támogató lehet a magyar népességben** $99\%$-os megbízhatósággal. Egyszerűen csak **az arány konfidencia-intervallum két határát kell felszorozni az $N=9772756$-os sokasági elemszámmal**.

```{r}
c(as.integer(0.174 * 9772756), as.integer(0.221 * 9772756))
```

Tehát Magyarországon $99\%$ valószínűséggel $170$ ezer és $216$ ezer fő közötti a Fidesz támogatók száma. Éljen! :)

A teljes népességre nézve vett Fidesz támogatottság vizsgálható ugyan ezzel a függvényével **regionális bontásban** is, most $95\%$-os megbízhatósággal.

```{r}
groupwiseMean(Fidesz ~ Region, data = ESS, na.rm = TRUE, digits = 4, conf = 0.95)
```

Az eredményből egyrészt látható, hogy a mintán belül a Fidesz támogatottsága az Dél-Dunántúlon csak 15.4%, míg Nyugat-Dunántúlon 16.7%. Kérdés, hogy ezek a különbségek a mintavételi hiba, azaz a 95%-os megbízhatóságú konfidencia-intervallum figyelembe vételével is megmaradnak-e!

Az eredményül kapott táblából szintén látható, hogy a **mintán belül a Fidesz támogatottsága az Dél-Alföldön csak 12.6%, míg Dél-Dunántúlon már 15.4%**. Azonban, ha a konfidencia-intervallum segítségével a **teljes népességet vizsgáljuk, akkor ez 95%-os valószínűséggel egy NEM szignifikáns** (jelentős) **eltérés, mivel a két konfidencia-intervallum metszi egymást!** Tehát a teljes népességben elképzelhető legjobb esetben egy 17.7%-as támogatottság is a Dél-Alföldön, míg a legrosszabb esetben belefér a Dél-Dunántúlon 9.4%-es támogatottság is. Tehát, az, hogy a Dél-Dunántúlon magasabb a Fidesz támogatottsági arány a mintában, az lehet csak a mintavételi hiba műve 95%-os megbízhatósággal! Ellenben az **Észak-Magyarországi Fidesz támogatottság 95% valószínűséggel a sokaságban is magasabb, mint a Dél-Alföldi**, hiszen a Dél-Alföldön a támogatottság legjobb esetben is csak 17.7%, míg Észak-Magyarországon legrosszabb esetben is már 20.4%. Tehát a **két konfidencia-intervallum NEM metszi egymást, a mintában mért eltérések 95% valószínűséggel megmaradnak a sokaságban is!**

Az eredményekről ugyan úgy készíthetünk egy olyan `ggplot` vizualizációt is, mint a pártpreferenciák szerint bontott átlagos netezési időkről a <a href="Chapter07.html" target="_blank">Section 6 of Chapter 7</a>-ben.

```{r}
conf_int_df <- groupwiseMean(Fidesz ~ Region, data = ESS, na.rm = TRUE, digits = 4, conf = 0.95)

library(ggplot2)

ggplot(conf_int_df, aes(x = reorder(Region,Mean), y=Mean, fill = Region)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=Trad.lower, ymax=Trad.upper)) + coord_flip() + labs(x="")
```

Az előbb taglalt, 95%-os megbízhatósággal a sokaságban is szignifikáns eltérés Dél-Alföld és Észak-Magyarország között. Az is látszik, hogy **hasonló szignifikáns különbség még** ezen kívül **Dél-Alföld és Budapest Fidesz támogatottsági aránya között található**.

### 2.1. Mintaelemszám meghatározása aránybecsléshez

Érdemes az arány konfidencia-intervallumának számítása során felhasználni azt az információt, hogy egy csak 0-ból és 1-ből álló változó korrigált mintaszórása $s=\sqrt{p(1-p)}$ módon számítható, ahol $p$ az $1$ értékek aránya a mintában!<br>
Nézzük is meg, hogy igaz-e ez! Ugyebár a Fidesz támogatottsági aránya a teljes 1849 elemű mintában $p=19.7\%$. Ez alapján a szórása a `Fidesz` nevű 0-1-ből álló változónak $s=\sqrt{p(1-p)}=\sqrt{0.197 \times (1-0.197)}=0.3977323$.

Nézzük meg az eredményt az `sd` függvénnyel is:

```{r}
sd(ESS$Fidesz)
```

A kétféleképp számolt érték némi kerekítési hibát leszámítva egyezik! :) De hát ez nem meglepő, hogy így alakult, hiszen a <a href="Chapter05.html" target="_blank">Section 5 of Chapter 5</a>-ben éppen azt mondtuk, hogy a mintaarányok (a $p$-k) standard mintavételi hibája a $SE(p) \approx \sqrt{\frac{p(1-p)}{n}}$ képlettel megadható. :)

Ez azt jelenti, hogy **az arány konfidencia-intervallumának hossza** a $\triangle = SE \times k$ képlet alapján $\sqrt{\frac{p(1-p)}{n}} \times k$ módon számítható, hiszen az átlag standard hibája $\frac{s}{\sqrt{n}}$ volt, és most felhasználtuk, hogy csak 0-1-et tartalmazó változókra $s=\sqrt{p(1-p)}$. A $k$ megbízhatósági szorzó pedig ugyan úgy $N(0,1)$ eloszlással számolható *nagy méretű minták esetén*, mint az átlag konfidencia-intervallumánál. Hiszen magas $n$ esetén a $t(n-1)$ eloszlás sűrűségfüggvénye már lényegében egybeesik az $N(0,1)$ eloszlás sűrűségfüggvényével, ahogy a <a href="Chapter07.html" target="_blank">Section 4 of Chapter 7</a>-ben is láttuk.

**Ennyi információ alapján pedig képesek vagyunk arra, hogy még mintavétel ELŐTT meghatározzuk, hogy az arány egy adott pontosságú és megbízhatóságú becsléséhez mekkora elemszámú mintára van szükségünk**.

Hiszen pl. $99\%$-os megbízhatósági szint mellett a szükséges megbízhatósági $k$ szorzó a standard normális, azaz $N(0,1)$ eloszlás inverz értéke alapján megadható $z_{1-\frac{\alpha}{2}}$ módon:

```{r}
alpha <- 1-0.99
qnorm(1-alpha/2)
```

Vegyük az értéket kerekítve $k=2.6$-nak!

Ugyebár azt tudjuk, hogy a jelenlegi 1849 elemű mintánk esetén Fidesz támogatottsági aránya $p=19.7\%$, **amitől a támogatottsági arány valós sokasági értéke** 99%-os valószínűséggel $\pm$ **2.4 százalékpontos hibahatárral térhet el**: $$\pm \triangle = SE \times k = \sqrt{\frac{p(1-p)}{n}} \times k = \sqrt{\frac{0.197 \times (1-0.197)}{1849}} \times 2.6=0.0240$$

De mi a helyzet, ha a **hibahatár értékét 1 százalékpontra akarom csökkenteni és meg akarom őrizni a 99%-os megízhatósági szintet**? Ekkor **nagyobb mintát kell venni, kérdés, hogy mennyivel nagyobbat**. Ezek alapján a kívánt $\triangle$ érték $0.01$ és a $k=2.6$ értékből sem akarok engedi. Azaz: $$0.01 = \sqrt{\frac{p(1-p)}{n}} \times 2.6$$

Ebből $n$-t kifejezve: $$n=\frac{2.6^2 \times p(1-p)}{0.01^2}$$

Ezen a ponton nagy a csábítás, hogy a képletből úgy számoljuk ki $n-t$, hogy $p=19.7\%$-kal dolgozzunk. De ezt **ne tegyük**! Mivel nem tudjuk, hogy a megnövelt elemszámú mintában mennyi is lesz $p$. Plusz, ha a **szükséges mintaelemszámot AZELŐTT akarjuk meghatározni, hogy a kérdéses $p$ arány becslésére már vettünk mintát, akkor aztán tényleg lövésünk nincs a $p$ értékéről**!

Szerencsére, **rájöhetünk, hogy a $p(1-p)$ kifejezésnek könnyen meg tudjuk adni a maximumát**, hiszen az $f(p)=p(1-p)=p-p^2$ függvény egy fordította parabola, melynek maximuma $p=0.5$-nél kerül felvételre és értéke $max(p(1-p))=0.25$:

<center>
![](p_SH.jpg){width=50%}
</center>

Szóval az $N=\frac{2.6^2 \times p(1-p)}{0.01^2}$ formulába **mindig beírhatjuk a $0.25$-öt, hiszen ez a legrosszabb szituációnk, ekkor lesz aránybecslés esetén maximális a standard hibánk**. Ha elégség nagy mintát veszünk, hogy a maximális $SH$ mellett is $\triangle = 0.01$-et érjünk el, akkor minden egyéb esetben is jók vagyunk.

Tehát, **az 1 százalékpontos hibahatár eléréséhez szükséges elemszám 99%-os megbízhatóság mellett** $N=\frac{2.6^2 \times 0.25}{0.01^2}=16900$ **fő**.<br>
Ennek fényében különsöen érdekes meglesni [ezen a linken](https://ig.ft.com/sites/brexit-polling/) hogy hány fős mintából dolgoztak a 2016-os Brexit népszavazás eredményének előrejelzése során a közvéleménykutatók, ahol lehetett tudni, hogy nagyon kiélezett a verseny a maradás és elszakadás pártok között, így a két párt támogatottsági arányának becslése során **nagyon szükség lett volna erre az 1 százalékpontos hibahatárra és a 99%-os megbízhatósági szintre, ami a 16900 elemű minták biztosítanak arányok becslése során**.

### 2.2. Szükséges minimális elemszám aránybecsléshez

Az **arány intervallumbecslés** esetén **van** a 2.1. fejezetben taglaltak mellett egy **minimális elemszám követelménye is, aminél kisebb mintákban az intervallumbecslés egyáltalán NEM elvégezhető!!**

Ez a követelemény abból jön, hogy az aránybecslést gyakorlatilag egy átlagbecslésre vezetjük vissza.<br>
Hiszen átlagbecslés esetén **kis elemszámú mintáknál feltételezzük az alapsokaság** (tehát, amiből a mintát vettük) **normális eloszlását, még akkor is, ha a megbízhatósági szorzót t-eloszlásból számítjuk!** Egy **csak $0$-ból és $1$-ből álló adatsor pedig bajosan fog normális eloszlást követni!** :)

Azt, hogy **mi számít aránybecslés esetén nagy mintának, a következő szabály adja meg**:

- Legyen az arány szempontjából *kedvező* esetek száma több, mint 10 a mintában, azaz: $n \times p >10$
- Legyen az arány szempontjából *kedvezőtlen* esetek száma is több, mint 10 a mintában, azaz: $n \times (1-p) >10$

Ez a Fidesz támogatók arányának korábbi példájára nézve úgy néz ki, hogy a teljes mintánk elemszáma $n=1849$ fő:

```{r}
nrow(ESS) # number of rows in the data frame
```

Míg az arány szempontjából *kedvező* esetek, azaz a Fidesz-KDNP támogatók száma $365$ fő:

```{r}
sum(ESS$Fidesz)
```

Tehát a **két feltétel itt a következőképpen teljesül**:

- A *kedvező* esetek száma $365 > 10 \rightarrow$ **feltétel teljesül**
- A *kedvezőtlen* esetek száma $(1849-365) = 1484 > 10 \rightarrow$ **feltétel teljesül**

Tehát, **mindkét feltétel teljesül**, a Fidesz támogatók arányának **intervallumbecslése elvégezhető** volt, mivel **megvan a minimális mintaelemszám**. Yeah! :)

## 3. A Bootstrap becslések általános elve

Eddig a konfidencia-intervallumokkal kapcsolatban elég könnyű dolgunk volt *úgymond*, mert az **átlag és arány esetében** is a konfidencia inztervallum hosszát ($\triangle$-t) ki tudtuk számolni standard hiba ($SE$) szorozva megbízhatósági szorzó ($k$) elven: $$\triangle=SE \times k$$

Azért tudott ez a formuula működni, mert a **standard hibára tudtunk adni egy egyszerű képletet** ($\frac{s}{\sqrt{n}}$ vagy $\sqrt{\frac{p(1-p)}{n}}$) és **a $k$-t ki tudtuk számolni valami konkrét eloszlásból** (standard normális vagy t-eloszlás).

NODE, **mi a helyzet ha ezek az eszközök NEM állnak rendelkezésre?** Tehát, mi van akkor, ha 

1. A standard hibáját egy statisztikai mutatónak (paraméternek, azaz $\theta$-nak) nem lehet egysezrű képlettel kiszámolni.
2. A $k$ számolásához nincs konkrét eloszlás, vagy ami van, az csak lehetetlen feltételekkel alkalmazható (pl. a vizsgált alapsokaság, amiből a mintát vettük az legyen normális eloszlású, mintamérettől függetlenül)

Ezekben az esetekben **segít rajtunk a Bootstrap becslés**! Nézzük meg ennek a módszernek **mi az általános alapelve az átlag standard hibáján keresztül**.

Ugyebár az átlag standard hibája úgy jön ki egy mintavételből, hogy fogjuk a minta korrigált szórását, $s$-t, és ezt elosztjuk a mintaelemszám ($n$) gyökével: $$SE(\bar{y})=\frac{s}{\sqrt{n}}$$

Számoljuk ki az `ESS` adatbázisból a napi netezési idő (`NetUsePerDay_Minutes` oszlop) átlagának standard hibáját! Csak emlékezzünk, hogy a `NetUsePerDay_Minutes` oszlopban volt pár hiányzó érték, ezeket ne vegyük figyelembe az $n$ meghatározásakor!

```{r}
n <- sum(!is.na(ESS$NetUsePerDay_Minutes)) # this way we do not consider the empty rows

corr_std <- sd(ESS$NetUsePerDay_Minutes, na.rm = TRUE) # with na.rm = TRUE, we do not consider the empty rows

SE_Formula <- corr_std / sqrt(n)
SE_Formula
```

Szuper, a mintaátlag várható eltérése a valós, sokasági átlagos netezési időtől várhatóan $\pm4.38$ perc!

**Hogyan jön ki ez az eredmény Bootstrap módon?**

A **Bootstrap becslés alapötlete a standard hiba alap definíciójából jön**, amit a <a href="Gyak03.html" target="_blank">3. heti tananyag 5. fejezetében néztünk</a>. **Vegyünk ki a sokaságból nagyon-nagyon sok** (pl. 1000 vagy 10000 db) **visszatevéses** (azaz FAE) **mintát, minden mintából számoljuk mi a mintaátlagot és a mintaátlagok szórása a standard hiba** az átlagbecslés *torzítatlanság*a miatt.<br>
Ugyebár ezzel a megközelítéssel az a **baj, hogy a gyakorlatban csak egyetlen egy darab mintánk van, és nem ismerjük a sokaságot, így nem tudunk belőle nagyon-nagyon sok FAE mintát kivenni**.<br>
Nos, a **Bootstrap módszer azt mondja, hogy ezt az alap szórás-elvű $SH$ számolást tudjuk SZIMULÁLNI akár egyetlen egy darab mintavételből is!**

Ha **van egy $n$ elemű mintánk, akkor abból vegyünk ki nagyon-nagyon sok (pl. 1000 db) szintén $n$ elemű FAE almintát!!** A **FAE, azaz visszatevéses elv miatt, az $n$ elemű alminták összetétele véletlenszerűen meg fog változni, és ezek a véletlen változások épp a mintavételi hiba tendenciáit követik le!!**<br>
Ezek után más dolgounk nincs, mint **kiszámolni minden almintából a mintaátlagot, és venni ezek sima, korrigálatlan szórását, és ez lesz a $SH$!!**

Lássuk akkor ezt a dolgot a gyakorlatban! **Számoljuk ki az átlag standard hibáját Bootstrap elven!**

Először is **vegyünk a `NetUsePerDay_Minutes` oszlopból mondjuk $1000$ db FAE mintát, és tároljuk le ezeket az almintákat egy olyan data frame-ben, aminek $1000$ sorában lesznek a különböző mintavételek, míg $n$ db oszlopában az $n$ db mintaelem minden egyes mintavételezési körben**.<br>
Itt gyakorlatilag ugyanazokat a megoldásokat követjük R-ben, mint a <a href="Chapter04.html" target="_blank">Section 3.1. of Chapter 4</a>.

Először elkészítünk egy olyan verziót az `ESS` data frame-ből, amiben **nincsenek benne a `NetUsePerDay_Minutes` oszlop hiányzó értékei**. Így egy $n=1099$ soros data frame-ünk lesz.

```{r warning = FALSE, message = FALSE}
ESS_Filter <- ESS[!is.na(ESS$NetUsePerDay_Minutes),]
sum(is.na(ESS_Filter$NetUsePerDay_Minutes))
```

Szuper, ezzel megvagyunk!

Akkor most **jöhet az $1000$ db $n=1099$ elemű alminta generálása `for` ciklusból** és a tárolás az újonnan létrehozott data frame-ben.<br>

Most is **megnövekedett futásidőre kell** itt **készülni**! :)

```{r warning = FALSE, message = FALSE, eval = FALSE}
# create the first subsample
set.seed(1992)
samples <- sample(ESS_Filter$NetUsePerDay_Minutes, size=nrow(ESS_Filter), replace = TRUE)

# add the remaining subsamples to new rows
for (index in 1:(10000-1)) {
  set.seed(1992+index)
  samples <- rbind(samples, sample(ESS_Filter$NetUsePerDay_Minutes, size=nrow(ESS_Filter), replace = TRUE))
}

samples <- as.data.frame(samples)

rownames(samples) <- paste0("Sample",1:10000)
colnames(samples) <- paste0("Element",1:nrow(ESS_Filter))

head(samples)
```

```{r warning = FALSE, message = FALSE, echo = FALSE}
samples <- read_excel("BootstrapData.xlsx")
rownames(samples) <- paste0("Sample",1:10000)
head(samples)
```

Akkor meg is van az $1000$ db almintánk! :) Számoljuk ki **mindegyik almintában a mintaátlagot**!<br>
**Figyeljünk** itt is arra, hogy mivel a data frame oszlopai folyamatosan bővülnek amjd, így manuálisan le kell szorítani a statisztikai függvények alkalmazását mindig az első $n=1099$ db oszlopra!

```{r}
samples$means <- apply(samples[,1:1099], 1, mean)
head(samples[,1098:1100])
```

A **standard hibánk pedig akkor ezeknek az alminta-átlagoknak lesz a sima korrigálatlan szórása**!

```{r}
class_sd <- function(x) {
  return(sqrt(mean((x-mean(x))^2)))
}

SE_Bootstrap <- class_sd(samples$means)

SE_Bootstrap
```

E voilá! Némi kerekítési hiba mellett ez kb. ugyan annyi, mint a $\frac{s}{\sqrt{n}}$ képlettel kapott verzió! :) Illetve, értelemszerűen **itt mindenki más értéket kaphatott, mert nem fixáltuk a véletlenszám generátor magját a mintavételek során**.

```{r}
c(SE_Formula, SE_Bootstrap)
```

Nyilván, ha **több almintát veszünk, akkor pontosabb lesz a közelítés**. Ezt úgy mondjuk szépen **szakszóval, hogy növeljük a Bootstrap becslés replikációinak számát**. :) Tehát a **replikációk száma az alminták számát jelenti**.

NODE, **mire volt jó, hogy ezt a fránya $SE$-t ilyen körülményesen számoltuk ki a képlet helyett?** Nos, **átlag esetében a világon SEMMIRE!**<br>
Viszont, ezzel a **Bootstrap elvvel ki tudjuk számolni pl. a napi netezési időnk mediánjának standard hibáját, amire amúgy NINCS olyan egyszerű képlet, mint az átlag standard hibájára!**<br>
Ugyebár ezt megtehetjük, mert megnéztük a <a href="Chapter05.html" target="_blank">Section 4 of Chapter 5</a>, hogy a medián is egy *torzítatlanul* becsülhető statisztikai paraméter, mint az átlag.

```{r}
SampleMedian <- median(ESS_Filter$NetUsePerDay_Minutes)
SampleMedian

samples$medians <- apply(samples[,1:1099], 1, median)
SE_Median <- class_sd(samples$medians)

SE_Median
```

Tehát tudjuk, hogy a megfigyelt $n=1099$ elemű mintában a medián napi netezési idő $120$ perc, és a **standard hibából tudjuk, hogy ez az érték a teljes magyar népesség** (sokaság) **valós medián napi netezési idejétől várhatóan $\pm11.69$ perccel különbözik**.

Innen pedig már csak egy lépés, hogy legyen valami $1-\alpha$ megbízhatósági szintű **konfidencia-intervallumunk a mediánra** ezzel a Bootstrap módszerrel!

## 4. A Medián Bootstrap intervallumbecslése

Ahhoz, hogy megtudjuk a Bootstrap módszerrel előállított $1000$ db alminta alapján a medián $1-\alpha$ megbízhatóságú konfidencia-intervallumát, akkor egyszerűen vennünk kell az **almintákból kiszámolt 1000 db medián adatsorának $\alpha/2$ és $1-\alpha/2$ percentiliseit!**<br>
Hiszen, az $1-\alpha$ megbízhatóságú konfidencia intervallumnak azt kell megadnia, hogy milyen két érték között mozoghat a valós, sokasági medián $1-\alpha$ valószínűséggel. Ezt pedig pl. **átlag esetében úgy állapítottuk meg, hogy vettük a sok-sok mintaátlag eloszlásának, konkrétan az $N\left(\mu, \frac{\sigma}{\sqrt{n}}\right)$ eloszlásnak a középső $1-\alpha$ százalékát!!**<br>
A **Bootstrap** mintavételezés segítségével pedig pont a **sok-sok minta-medián eloszlását akartuk szimulálni, tehát ennek kell venni a középső $1-\alpha$ százalékát!** Ezt pedig a minta-medián értékek $\alpha/2$ és $1-\alpha/2$ percentilisei adják ki.

Nézzük is meg az eredményt a netezési idők mediánjának $95\%$-os megbízhatóságú konfidencia-intervallumára! Pythonban a data frame `Medianok`-nak elnevezett oszlopának `quantile` metódusát tudjuk használni a keresett két percentilis kiszámításához.<br>
Ugyebár ekkor $1-\alpha=95\%=0.95$, tehát $\alpha=0.05=5\%$:

```{r}
alpha <- 0.05
quantile(samples$medians, probs = c(alpha/2, 1-alpha/2))
```

Tehát, a **teljes magyar népesség körében a medián napi netezési idő $120$ és $150$ perc között van $95\%$ valószínűséggel.**.

Az eredményből láthatjuk, hogy a medián konfidencia-intervalluma **NEM szimmetrikus a minta egészéből számított mediánra (ami szintén 120 perc volt, mint itt az alsó határ), mint ahogy az átlag konfidencia-intervalluma a minta egészéből számított átlagra szimmetrikus volt**!

Ennek hátterében az áll, hogy a **minta-mediánok eloszlása nem szép szimmetrikus normális eloszlás, mint a mintaátlagoké**. Ez a szimulált alminták átlagainak és mediánjainak hisztogramjaiból rögtön szépen látszódik.

```{r}
hist(samples$means)
hist(samples$medians)
```

És tényleg: a mediánok esetében a szimulált mintavételi eloszlás nagyon koncentrál a $120$-ra, míg az átlag esetében megkapjuk a jól ismert, csudiszép normális eloszlásunkat! :)<br>
Medián esetén a torzabb eloszlás kép részben összefügg azzal, amit Fundamentals of Statistics-ben tanultunk: kis értékkészletű ismérvre a medián nem túl informatív mutatószám! Mindenesetre ezt a "torzságot" a Bootstrap elven számolt konfidencia-intervallumkezeli. :)

Egyébként le is tudjuk csekkolni, hogy **átlag esetében a Bootstrap elven számított $95\%$-os megbízhatóságú konfidencia-intervallum ugyan azt az eredményt hozza némi kerekítési hibával, mint a standard normális eloszlású megbízhatóságú szorzóval dolgozó konfidencia-intervallum számolás**. Ugyebár most $n=1099$ nagy minta, így mindegy, hogy normális eloszlású megbízhatóságú szorzóval dolgozunk vagy t-eloszlásúval.

```{r}
# formula with confidence multiplier from t-distribution
groupwiseMean(NetUsePerDay_Minutes ~ 1, data = ESS, conf = 0.95,na.rm = TRUE, digits = 4)
  
# Boostrap version
quantile(samples$means, probs = c(alpha/2, 1-alpha/2))
```

Tényleg, csak minimális eltérés van a két eredmény között, ami amúgy csökkenthető, ha a Bootstrap módszerben több almintával, azaz magasabb replikációszámmal dolgozunk.

Szerencsére, a **Bootstrap konfidencia intervallum**okat nem kell mindig ilyen szenvedős módon kiszámolni Pythonban, mint ahogy most tettük a külön data frame generálásra `for` ciklusból az almintáknak, hanem **a `boot` csomagban létezik rá egy beépített függvény nagyon krevatívan `boot` néven**. Ennek az is az előnye, hogy a **futásideje is sokkal jobb, mint a mi összebarkálcsolt megoldásunknak**. Hiszen ezen a függvényen több fejlesztő is dolgozott több hónapot, halálra van az egész kód mögötte optimalizálva.

Let's install and include the package to our R environment:

```{r eval=FALSE}
install.packages("boot")
library(boot)
```

```{r echo=FALSE}
library(boot)
```

Az ezen belül lakó `boot` függvény paraméterei a következőképpen működnek:

1. Megadjuk az **adatsort vektor formátumban, amiből** majd a Bootstrap **almintákat kell generálni**.
2. Megadjuk annak a **statisztikai paraméter**nek (mutatószámnak) az R-ben lévő függvényét, **amire a konfidencia-intervallumot** akarunk számolni.
3. A **replikációszám**ot egy `R` paraméterben lehet variálni, de mivel alapesetben $10000$ db almintát készít a függvény, így **nem érdemes ebbe manuálisan belenyúlni ebbe a paraméterbe**. A $10000$ replikáció általában elég szokott lenni. :)

Lássuk akkor a függvényt akcióban, a napi netezési idők mediánjának $95\%$-os megbízhatóságú konfidencia-intervalluma esetében!

```{r}
bootMedian <- function(data, indices) median(data[indices])

set.seed(1992)
boot_result <- boot(ESS_Filter$NetUsePerDay_Minutes, bootMedian, R=10000)
boot_result
```

E voilá! Megvan a korábban látott $11.7$ perc körüli $SE$! :)

A `type` paraméterben kikötjük, hogy ugyan úgy **precentilisekkel határozza meg a konfidencia-intervallumot** a gépszellem, ahogyan mi is tettük ezt manuálisan. Itt is van a $120-150$ perces konfidencia-intervallum.

```{r}
boot.ci(boot_result, conf = 0.95, type = "perc")
```


## 5. A Szórás Bootstrap intervallumbecslése

A szórás $1-\alpha$ konfidencia-intervallumára van egy zárt formulás képletünk, ami elég egyszerűen néz ki: $$P\left(\sqrt{\frac{(n-1)s^2}{\chi^2_{\alpha/2}(n-1)}}< \sigma <\sqrt{\frac{(n-1)s^2}{\chi^2_{1-\alpha/2}(n-1)}}\right) = 1 - \alpha$$

A képletben a $\chi^2(n-1)$ az egyetlen ismeretlen betű. Ez azért van itt, mert a mintaszórásnégyzetek eloszlása egy $n-1$ szabadságfokú $\chi^2$-eloszlás, úgy mint ahogy a mintaátlagok eloszlása egy $n-1$ szabadságfokú $t$-eloszlás, ha a sokasági szórást nem ismerjük előre.<br>
A $\chi^2(df)$-eloszlás egy **jobrra elnyúló normális eloszlás**. Az **elnyúlás mértékét a szabadságfoka** (angolul degrees of freedom = $df$) **szabályozza: minél nagyobb a szabadságfok, annál kevésbé jobbra elnyúló az eloszlás**:

<center>
![](chisqrdist.jpg){width=50%}
</center>

A $\chi^2_{\alpha/2}(n-1)$ és $\chi^2_{1-\alpha/2}(n-1)$ értékek egy $n-1$ (mintaelemszám mínusz egy) szabadságfokú $\chi^2$-eloszlás **inverz értékei $\alpha/2$ és $1-\alpha/2$ aláesési valószínűségek mellett**. Ezeket R-ben kiszámolni pofon egyszerű, hiszen van beépített függvény rá, teljesen logikusan a normális, exponenciális és t-eloszlások után `qchisq` néven. A függvény első paramétere az ismert alá esési valószínűség, második paramétere a szabadságfok, pont mint a `qt` esetében.

A konfidencia-intervallum ezek után pedig csak annyi, hogy kiindulunk a mintaelemszám mínusz egy szorozva korrigált mintabeli szórásnégyzet ($(n-1)s^2$) értékből, és azt leosztjuk az intervallum alsó határához $\chi^2_{1-\alpha/2}(n-1)$-gyel, a felső határához pedig $\chi^2_{\alpha/2}(n-1)$-gyel, és az egész hányadosból gyököt vonunk.

Nézzük meg az elvet **alkalmazás közben a napi netezési idők szórásának $97%$-os megbízhatóságú konfidencia-intervallumára**!<br>
Arra emlékezzünk csak technikai oldalon, hogy a $\chi^2_{\alpha/2}(n-1)$ ad majd kisebb inverz értéket, így ővele a felső határnál kell osztani (hogy az eredmény nagyobb legyen), míg a $\chi^2_{1-\alpha/2}(n-1)$ érték ad magasabb inverz értéket, így ővele az alsó határnál kell osztani (hogy az eredmény kisebb legyen).

```{r}
# Get corrected sample standard deviation
s <- sd(ESS_Filter$NetUsePerDay_Minutes)
s

# Get the confidence interval
n <- nrow(ESS_Filter)
alpha <- 1-0.97

chisq_low <- qchisq(alpha/2, df = (n-1))
chisq_upp <- qchisq(1-alpha/2, df = (n-1))

common_numerator = (n-1)*(s^2)

c(sqrt(common_numerator/chisq_upp), sqrt(common_numerator/chisq_low))
```

Tehát, a megfigyelt mintában a napinetezési idők szórása $145.2$ perc, ami a **teljes magyar népesség körében $97\%$ valószínűséggel $138.8$ és $152.3$ perc között mozoghat**.

Érdemes megfigyelni, hogy a **konfidencia-intervallum NEM szimmetrikus a mintából számított szórásra azaz $s$-re, mint ahogy az átlag konfidencia-intervalluma a minta egészéből számított átlagra szimmetrikus volt**! Közelebb van valamivel a mintából számolt szórás ($s$) a konfidencia-intervallum alsó határához, mint a flsőhöz! Itt ennek az oka az, hogy **a $\chi^2$-eloszlás egy jobbra elnyúló eloszlás**, tehát azt gondolja, hogy a kisebb értékek jellemzőek inkább a mintaszórások eloszlására, így **a mintából mért szórást ($s$-t) is inkább a konfidnecia-intervallum "aljára teszi"**.

Ez mind szép és jó, de **ez a $\chi^2$-eloszlásos konfidencia-intervallum képlet jelen esetben feltételezi, hogy az adatsor, amiből a mintát vettük** (tehát a napi netezési idők) **az normális eloszlású a sokaságban!!!** Ez pedig marhára **NEM TELJESÜL, ahogy azt egy gyors hisztogram készítés után láthatjuk is!**

```{r}
hist(ESS_Filter$NetUsePerDay_Minutes)
```

**Jobbra elnyúló** ez az időeloszlás, mint a fene. Ebből aztán semmilyen sokaságban **NEM** lesz **szép szimmetrikus normális eloszlás**!

Tehát, a **szórás konfidencia-intervallum képlete nem reális eredményeket mutat a valós, sokasági szórásra, mert a képlet mögötti feltételezés NEM teljesül!**<br>
Mit lehet tenni? **Hát alkalmazzuk a Bootstrap becslést, mivel annak semmilyen csúnya előfeltétele nincs**. Csak az kell itt is, hogy az eredeti sokaságból FAE mintavételünk legyen, de megbeszéltük a <a href="Gyak04.html" target="_blank">4. heti tananyag 4. fejezetének 2. feladatában</a>, hogy az ESS2020 mintavétel esetén ez a FAE mintavétel feltételezhető.

Szóval, akkor csináljuk meg a Bootstrap becslést a napi netezési idők szórására is, $97\%$-os megbízhatósági szinten! A beépített `scipy` csomagos függvénnyel most is simán tudunk dolgozni, mint a medián esetében is tettük:

```{r}
boot_sd <- function(data, indices) sd(data[indices])

set.seed(1992)
boot_sd_result <- boot(ESS_Filter$NetUsePerDay_Minutes, boot_sd, R = 10000)
boot.ci(boot_sd_result, conf = 0.97, type = "perc")
```

Ez alapján pedig a **napi netezési idők szórása a teljes magyar népesség körében $97\%$ valószínűséggel $131.3$ és $159.7$ perc között mozoghat**. Ami érdemben más, mint a $\chi^2$-es formulából kapott $138.8$ és $152.3$ perc közötti intervallum, de a **Bootstrap verzió a reálisabb, hiszen az NEM feltételezi a netezési idők normális eloszlását a teljes sokaságban!**

Szóval ez a Bootstrap becslés elég menő dolog. Pl. **lehet vele intervallumbecslést készíteni átlag esetében is kis mintákra** ($n\leq 30$), **amikor a mintavételezett adatsor eloszlása asokaságban NEM normális eloszlású és NEM tudjuk a valós sokasági szórást:**

<center>
![](BootstrapMeme.png){width=35%}
</center>