---
title: "Confidence Intervals in SR and Stratified Samples"
author: "László Kovács"
date: "16/03/2025"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
---

<style>
body {
text-align: justify}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Confidence Intervals for Simple Random Sampling without Replacement (SR Samples)

In the previous chapters, we have consistently worked with IID (Independent, Identically Distributed Samples or in other words, Random Sampling *with Replacement*). Now, let’s examine what happens when we have a **random sample without replacement**, i.e., a **SR** Sample.

Our reasoning starts from the fact that if the sampling fraction is small, meaning **if we select only a very small percentage of the entire population, then IID and SR are essentially the same**. In this case, even with IID, the probability of actual repetitions due to replacement is very low, meaning it is unlikely that the same unit is selected multiple times in our sample.

The **selection ratio**, using our previous notation, is denoted as $\frac{n}{N}$. Thus, if $\frac{n}{N} \rightarrow 0$, then $IID \approx SR$.

However, if $frac{n}{N}$ takes a larger value, then the **SR sample should be more precise, meaning it should have a smaller sampling error than the IID sample**, because every sampled observation in SR brings in new information, while in IID, redundant selection can occur due to replacement.

We **incorporate this fact into our confidence interval formulas** by simply multiplying the standard error formulas learned for IID by $\sqrt{1-\frac{n}{N}}$. Thus: $$SE_{SR}=SE_{IID} \times \sqrt{1-\frac{n}{N}}$$

This formula achieves what we need because:

1. **If the selection ratio is very close to $0$**, then we are multiplying $SE_{IID}$ by approximately $1$, meaning we do **not change it at all**.
2. **If the selection ratio is noticeably greater than $0$**, then we multiply $SE_{IID}$ by a number between $0$ and $1$, which ensures that the **product is always smaller than the original $SE_{IID}$**.

If you don’t believe it, feel free to **plot the SR correction factor, $\sqrt{1-\frac{n}{N}}$, in R** with `ggplot` for different values of the selection ratio $\frac{n}{N}$.

```{r}
# Empty vector for SR correction factors
SR_Vec <- c()
# Vector for the examined selection ratios
# Ratios between 0% and 90% with a setp size of 10%-points 
SelectionRatios <- seq(0, 0.9, 0.1)

# Start loop
for (CurrentSelectionRatio in SelectionRatios) {
  SR_Vec <- c(SR_Vec, sqrt(1-CurrentSelectionRatio))
}

# Arrange selection ratios and correction factors into a unified data frame
SR_Data <- data.frame(SelectionRatio=SelectionRatios,
                      CorrectionFactor=SR_Vec)

# Plot on a line chart with 'ggplot2'
library(ggplot2)
ggplot(SR_Data, aes(x=SelectionRatio, y=CorrectionFactor)) + geom_line()
```

You can see that as the sampling fraction increases, a smaller percentage of $SE_{IID}$ is taken when calculating $SE_{SR}$. Hooray! :)

Now, let’s see this entire system in practice for interval estimation of the mean in a large-sample case!

### 1.1. Confidence Interval for the Mean in SR Sample

Let’s load the contents of the Excel file <a href="https://github.com/KoLa992/Statistical-Modelling-Lecture-Notes/blob/main/Households_Income.xlsx" target="_blank">Households_Income.xlsx</a> into a data frame!<br>
In the table, we see the two variables (columns) of $n=8306$ Hungarian households:

1. The type of settlement where the household is located (Village, Town, City, Budapest)
2. The household's annual income in 2019, expressed in thousand HUF

The data comes from the <a href="https://www.ksh.hu/eletmod" target="_blank">HCSO Income and Living Conditions Survey</a>. According to the linked description by HCSO, the **data can be treated as a simple random sample without replacement (SR) from the population of Hungarian households**.<br>
Based on this, an important piece of information is that in 2019, the **total number of Hungarian households was $N=4111240$**.

```{r}
library(readxl)
HH <- read_excel("Households_Income.xlsx")
str(HH)
```


Great! We have found our two desired columns for all $n=8306$ households, plus an *ID* column at the beginning, which we won’t be using for anything. :)

Now we can confidently apply the well-known sample *mean ± delta* method, i.e., $\bar{y} \pm \triangle$, to estimate the $99\%$ confidence interval for the average household income. Since in the formula $\triangle = k \times SE$, due to the large sample size $n=8306$, the confidence multiplier can be taken directly from the standard normal distribution, meaning $k = z_{1-\frac{\alpha}{2}}$. The standard error $SE$ in this case is the standard error for an SR sample, which, based on the previous chapter, can be given as $SE_{IID} \times \sqrt{1-\frac{n}{N}}$, and of course we all know that for the mean $SE_{IID}=\frac{s}{\sqrt{n}}$.

```{r}
N <- 4111240
n <- nrow(HH)

sample_mean <- mean(HH$Income)
s <- sd(HH$Income)

alpha <- 1-0.99
k_z <- qnorm(1-alpha/2)

SE_SR <- s/sqrt(n)*sqrt(1-n/N)

# conf interval
c(sample_mean - k_z*SE_SR, sample_mean + k_z*SE_SR)
```

Thus, treating this Household data as a simple random sample without replacement, we obtain that **the average annual income of a Hungarian household is** between $4568$ and $4730$ thousand HUF, meaning **between $4.5$ and $4.7$ million HUF with $99\%$ probability**.

Our selection ratio here is very small: $\frac{n}{N}=\frac{8306}{4111240}=0.002$, so the result is essentially the same as if we had performed the entire calculation without the SR correction factor.

```{r}
SE_IID <- s/sqrt(n)

# conf interval
c(sample_mean - k_z*SE_IID, sample_mean + k_z*SE_IID)
```

Thus, the expected annual income is still approximately between $4.5$ and $4.7$ million HUF with $99\%$ confidence.

### 1.2. Confidence Interval for the Proportions in SR Sample

The same logic works perfectly well for proportion estimation as well. This is no coincidence, as we clarified in <a href="Chapter08.html" target="_blank">Chapter 8</a> that a proportion, as a statistical measure, is actually the mean of a variable where observations possessing the examined characteristic are coded as $1$, while all others are coded as $0$.

Let's create this $\{0,1\}$ variable in a new column, which will allow us to estimate the proportion of Budapest households.

```{r}
HH$isBP <- ifelse(HH$Settlement=="Budapest", 1, 0)
mean(HH$isBP)
```

Great, we are done! In the observed sample, the proportion of Budapest households is $18.55\%$.

Now, if we apply the confidence interval formula from Section 1.1 to this new column, incorporating the correction factor $\sqrt{1-\frac{n}{N}}$, we **obtain the $99\%$ confidence interval for the proportion of Budapest households in the population**.

```{r}
sample_prop <- mean(HH$isBP)

SE_Prop_SR <- sqrt(sample_prop*(1-sample_prop)/n)*sqrt(1-n/N)

# conf interval
c(sample_prop - k_z*SE_Prop_SR, sample_prop + k_z*SE_Prop_SR)
```

Thus, **approximately $17.5\% - 19.6\%$ of all Hungarian households are located in Budapest**, with $99\%$ confidence.

## 2. Confidence Interval for the Mean from Proportionally Stratified (PS) Sample

The HCSO does not simply state that the HH database is a simple random sample (SR) from Hungarian households; rather, it specifies that it is a **proportionally stratified sample based on settlement type**. This means that **separate SR samples were taken from the four types of settlements** (Budapest, Large City, Other Towns, Villages) in **such a way that their proportions in the final sample of $n=8306$ elements match their proportions in the entire population** (i.e., all Hungarian households). Thus, the sample is perfectly representative regarding settlement type.

The essence of this sampling technique is that if we **want to estimate the average annual income of Hungarian households, then in the standard error calculation, we do NOT need to account for income variation BETWEEN settlement types**! This is because this **between variation is already handled by the separate sampling within each settlement type**!<br>
Meaning that **instead of the formula** $$SE_{SR} = \frac{s}{\sqrt{n}} \times \sqrt{1-\frac{n}{N}}$$

It is sufficient to compute the standard error using only the **within-strata corrected sample standard deviation**, denoted as $s_w$: $$SE_{PR} = \frac{s_w}{\sqrt{n}} \times \sqrt{1-\frac{n}{N}}$$

To understand this formula, we need to know that **the total (corrected) variance of a numerical variable can be decomposed into the sum of between variance (between strata) and within variance (within strata)**.

In the following formulas, the index $j$ denotes the $j$-th stratum, and the number of strata is denoted by $M$, so $j=1,2,...,M$ and $n=\sum_{j=1}^M{n_j}$.

The **within standard deviation is obtained through the within variance**, i.e., the within squared deviation. This is calculated as the **weighted average of the squared deviations $s_j^2$ within each stratum, weighted by $n_j-1$**. $$s_w^2=\frac{\sum_j{(n_j-1)s_j^2}}{n-1}$$

The internal standard deviation is simply the square root of the internal variance: $s_w=\sqrt{s_w^2}$. In general, $s_w$ represents **how much a randomly chosen observation's variable value is expected to deviate from the mean of their own stratum**.

On the other hand, the between standard deviation is also calculated through its squared deviation, the between variance. The between variance is the **weighted corrected variance of the stratum means $\bar{y}_j$, weighted by $n_j$, around the overall mean $\bar{y}$**: $$s_b^2=\frac{\sum_j{n_j(\bar{y}_j-\bar{y})^2}}{n-1}$$


The between standard deviation is simply the square root of the between variance: $s_b=\sqrt{s_b^2}$ In general, $s_b$ **represents how much a stratum's mean is expected to deviate from the overall mean of the numerical variable**.  

From these two components, we can compute the **total corrected sample variance** as: $s^2=s_w^2+s_b^2$ The total standard deviation is then the square root of this quantity: $s=\sqrt{s^2}=\sqrt{s_w^2+s_b^2}$ **Since we cannot take square roots term by term, this relationship does NOT hold for standard deviations!**

The total standard deviation generally indicates **how much a randomly chosen individual's variable value is expected to deviate from the overall mean of the numerical variable, independent of stratification**.

**Now, let's imagine these different standard deviations visually as distances.** The following figure illustrates a simplified system where the stratifying variable creates only two groups (*oranges* and *greens*), rather than the four settlement types used in our example.

<center>
![](varhanyad1.png){width=80%}
</center>

<br>So, visually, we should think about the different $s$ values as follows::

- $s_w$: Average distance of one observation from its own stratum's mean
- $s_b$: Average distance of strata means from the overall mean
- $s$: Average distance of one observation from the overall mean

Based on this, in terms of stratification —i.e., the explanatory power of the qualitative variable used for the strata— it is best if, for a **fixed** $s$, $s_b$ is **large** and $s_w$ is **small**. This is because in this case, the **strata means are far from the overall mean** and thus, implicitly **far from each other**, while individual **observations deviate only slightly from their own stratum's mean**.

<center>
![](varhanyad2.png){width=30%}
</center>

In this case, as the figure illustrates, our grouping (i.e., stratification) has strong explanatory power! Therefore, we want $s$ to be composed mostly of $s_b$. However, since the property that the total **variance** equals the **sum of between and within variance** holds only for variance (not for standard deviation), we **look at the ratio of $\frac{s_b^2}{s^2}$ and we want this ratio to be large**!

The essence of stratified sampling is that **we take an independent SR sample from each stratum**. As a result, the **between-stratum variance** $s_b^2$ **does not need to be accounted for in the standard error calculation**, only the within variance. Applying this in the original $SE_{SR}$ formula, we get the standard error formula for the mean under proportionally stratified (PS) sampling: $$SE_{PR} = \frac{s_w}{\sqrt{n}} \times \sqrt{1-\frac{n}{N}}$$

Stratification is therefore most effective when **the variance between strata accounts for a large proportion of the total variance of the examined variable**, because only then can we say that **the estimation error of the proportionally stratified sample is smaller than that of an SR** (or an IID sample): $SE_{PR} \leq SE_{SR}$

Now, let's test this in practice!

We know that the average annual household income in the entire Hungarian population is likely between $4.5$ and $4.7$ million HUF with $99\%$ probability, assuming we treat the **HKF data as an SR sample**. We computed the $SE$ using the $SE_{SR}=\frac{s}{\sqrt{n}} \times \sqrt{1-\frac{n}{N}}$ formula here.

```{r}
N <- 4111240
n <- nrow(HH)

sample_mean <- mean(HH$Income)
s <- sd(HH$Income)

alpha <- 1-0.99
k_z <- qnorm(1-alpha/2)

SE_SR <- s/sqrt(n)*sqrt(1-n/N)

# conf interval
c(sample_mean - k_z*SE_SR, sample_mean + k_z*SE_SR)
```

However, the PS sample suggests that, in the standard error term $\frac{s}{\sqrt{n}}$, **it is sufficient to use only the within-settlement-type standard deviation, $s_w$**. For this, we need an **aggregated auxiliary (helper) table by settlement type** that includes:

- **sample sizes** ($n_j$)
- **sample means** ($\bar{y}_j$)
- **corrected sample standard deviations** ($s_j$)
- **population sizes** ($N_j$)

We can see that the settlement types, i.e., the **strata of the stratified sample, are denoted by the index $j$**.

```{r}
helper_table <- aggregate(Income ~ Settlement, data = HH, FUN = mean)
helper_table$sd <- aggregate(Income ~ Settlement, data = HH, FUN = sd)[,2]
helper_table$sample_size <- table(HH$Settlement)
helper_table
```

However, for the sake of completeness, **let’s supplement** the aggregated helper table with the **population sizes**. Here, we **take advantage of the fact that this is a proportionally stratified sample**. That is, the population size of each stratum is proportional to the total population size in the same way as the sample size of each stratum is proportional to the total sample size: $$\frac{n_j}{n} = \frac{N_j}{N}, \forall j$$

From this, we can quickly calculate the population size for each stratum, since we know that $N=4111240$ households in total. At the end, of course, we round the $N_j$-values to integers.

```{r}
helper_table$pop_size <- round(helper_table$sample_size/n * N, 0)
helper_table
```

Now we are done with this step as well. Everything is ready to calculate the within-group standard deviation using the following formula. $$s_w=\sqrt{\frac{\sum_j{(n_j-1) \times s_j^2}}{n-1}}$$

We can quickly compute this in R using standard vector operations.

```{r}
within_sd <- sqrt(sum((helper_table$sample_size-1)*helper_table$sd^2)/(n-1))
within_sd
```

So, **the expected deviation of a specific household’s annual income from its own settlement type’s average income is approximately** $s_w=\pm 2.849$ million HUF (2849 thousand HUF) in the observed sample.

Once we have the within-group standard deviation, we can quickly obtain the **proportionally stratified standard error**, which is about **0.298 thousand HUF** (298 HUF) **smaller than the standard error calculated using simple SR sample**.

```{r}
SE_PS = within_sd/sqrt(n) * sqrt(1-n/N)
c(SE_SR, SE_PS)
SE_PS-SE_SR
```

This causes **slightly narrower -i.e. smaller- confidence interval error margin for the $99\%$ confidence interval** as the formula we have here is $\triangle=SE_{PS} \times z_{1-\frac{\alpha}{2}}$.

```{r}
c(sample_mean - k_z*SE_PS, sample_mean + k_z*SE_PS)
```

With proportional stratification, the **confidence interval with confidence level unchanged shrinks** from $4567–4730$ thousand HUF to $4568–4729$ thousand HUF.

Alright, let’s not fool ourselves: **this is practically zero reduction in both the standard error and $\triangle$!** So, the **PS** sampling method was almost useless. **Why is that? Let’s see the explanation!**

### 2.1. Efficiency of PS Sampling

The effectiveness of proportionally stratified sampling ($PS$) compared to simple random sampling ($SR$) depends on **how much of the between variance can be omitted by using only the within-strata variance in the standard error** instead of the total variance. This is **determined by the extent to which the stratification variable explains the variation of the quantitative variable whose mean we aim to estimate**.<br>
We need a measure called the **variance ratio**: $$\eta^2 = \frac{s_b^2}{s^2} = 1-\frac{s_w^2}{s^2}$$

And indeed, when calculated using this formula, we can see that **the type of settlement barely determines the variation of household annual income**.

```{r}
round((1-within_sd^2/s^2) * 100, 2)
```

Settlement type explains only $1.88\%$ of income variation. This **exactly equals the percentage by which PS sampling reduces the squared standard error of SR**.

```{r}
round((SE_PS^2/SE_SR^2 - 1) * 100, 2)
```

Putting it differently, **proportional stratification reduces $SE^2$ by the percentage given by $1-\\eta^2$**. From now on, we call this reduction the **relative efficiency**, i.e.: $$Rel=\frac{SE_{PS}^2}{SH_{SR}^2}=1-\eta^2=\frac{s_w^2}{s^2}$$

These relationships can also be computed nicely in R.

```{r}
(SE_PS^2/SE_SR^2)
within_sd^2/s^2
```

Thus, due to **proportional stratification, the squared standard error is reduced to only $98.2\%$** of its original value.

Of course, the percentage by which the **standard error itself decreases** is given by the **square root of the relative efficiency**.

```{r}
(SE_PS/SE_SR)
within_sd/s
```

So, the **standard error decreases to only $99.05\%$**, meaning it **only drops by $0.95\%$**, because **the stratification variable (settlement type) explains just $1.88\%$ of the variation in annual income—the variable** (the mean of which we aimed to estimate).

Nonetheless, the **relationship between the standard errors of the three sampling methods** —IID, SR, and PS— can be expressed as follows: $$SE_{IID} \geq SE_{SR} \geq SE_{PS}$$

This holds because the SR standard error is slightly smaller than IID due to the correction factor $\sqrt{1-\frac{n}{N}}$, and the PS standard error is slightly smaller than SR because it uses only within-strata variance instead of total variance in the $SE$ formula. $$\frac{s}{\sqrt{n}} \geq \frac{s}{\sqrt{n}} \times \sqrt{1-\frac{n}{N}} \geq \frac{s_w}{\sqrt{n}} \times \sqrt{1-\frac{n}{N}}$$